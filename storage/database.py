#!/usr/bin/env python3
"""
–ü–û–õ–ù–´–ô –ú–û–î–£–õ–¨ –†–ê–ë–û–¢–´ –° –ë–ê–ó–û–ô –î–ê–ù–ù–´–•
–í–µ—Ä—Å–∏—è: 2.0
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç SQLite –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤, —É—Ä–æ–≤–Ω–µ–π, —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫
–ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π —á–µ—Ä–µ–∑ asyncio.to_thread
"""

import sqlite3
import json
import logging
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Union
from pathlib import Path
import pandas as pd
import traceback
from contextlib import asynccontextmanager

logger = logging.getLogger(__name__)

# ============================================================================
# –ö–õ–ê–°–° DATABASE MANAGER
# ============================================================================

class DatabaseManager:
    """
    –ú–µ–Ω–µ–¥–∂–µ—Ä –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö SQLite.
    
    –•—Ä–∞–Ω–∏—Ç:
    - –¢–æ—Ä–≥–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã (signals)
    - –£—Ä–æ–≤–Ω–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏/—Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è (levels)
    - –†—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (market_data)
    - –ù–∞—Å—Ç—Ä–æ–π–∫–∏ (settings)
    - –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ü–∏–∫–ª–æ–≤ (cycle_results)
    - –û—à–∏–±–∫–∏ (errors)
    
    –í—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º asyncio.to_thread.
    """
    
    VERSION = "2.0.0"
    
    def __init__(self, db_path: str = "data/trading_bot.db", 
                 backup_enabled: bool = True,
                 backup_interval_hours: int = 6):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –ë–î.
        
        Args:
            db_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            backup_enabled: –í–∫–ª—é—á–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ
            backup_interval_hours: –ò–Ω—Ç–µ—Ä–≤–∞–ª —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –≤ —á–∞—Å–∞—Ö
        """
        self.db_path = db_path
        self.backup_enabled = backup_enabled
        self.backup_interval_hours = backup_interval_hours
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –ë–î, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        db_dir = Path(db_path).parent
        db_dir.mkdir(parents=True, exist_ok=True)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'signals_saved': 0,
            'levels_saved': 0,
            'market_data_points': 0,
            'queries': 0,
            'errors': 0
        }
        
        # –ö–µ—à –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–µ–∫
        self.settings_cache = {}
        self.cache_ttl = timedelta(seconds=60)
        self.cache_timestamp = None
        
        logger.info(f"‚úÖ DatabaseManager v{self.VERSION} –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {db_path}")
    
    async def initialize(self):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö (—Å–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü)."""
        await self._init_db()
        logger.info("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    
    async def _init_db(self):
        """–°–æ–∑–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ç–∞–±–ª–∏—Ü—ã, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç."""
        create_tables_sql = """
        -- –¢–∞–±–ª–∏—Ü–∞ —Å–∏–≥–Ω–∞–ª–æ–≤
        CREATE TABLE IF NOT EXISTS signals (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            symbol TEXT NOT NULL,
            signal_type TEXT NOT NULL,
            direction TEXT NOT NULL,
            strength TEXT NOT NULL,
            price REAL NOT NULL,
            confidence REAL,
            stop_loss REAL,
            take_profit REAL,
            risk_reward_ratio REAL,
            timeframe TEXT,
            indicators_json TEXT,
            levels_json TEXT,
            confluence_json TEXT,
            description TEXT,
            metadata_json TEXT,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
            executed BOOLEAN DEFAULT FALSE,
            profit_loss REAL,
            notes TEXT
        );

        -- –¢–∞–±–ª–∏—Ü–∞ —É—Ä–æ–≤–Ω–µ–π
        CREATE TABLE IF NOT EXISTS levels (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            symbol TEXT NOT NULL,
            timeframe TEXT NOT NULL,
            level_type TEXT NOT NULL,
            price REAL NOT NULL,
            strength TEXT,
            confidence REAL,
            touches INTEGER DEFAULT 0,
            volume_profile REAL,
            calculation_method TEXT,
            cluster_size INTEGER DEFAULT 1,
            first_touch_time DATETIME,
            last_touch_time DATETIME,
            broken BOOLEAN DEFAULT FALSE,
            broken_time DATETIME,
            retests INTEGER DEFAULT 0,
            metadata_json TEXT,
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            expires_at DATETIME,
            UNIQUE(symbol, timeframe, level_type, price, created_at)
        );

        -- –¢–∞–±–ª–∏—Ü–∞ —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–∫–µ—à)
        CREATE TABLE IF NOT EXISTS market_data (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            symbol TEXT NOT NULL,
            timeframe TEXT NOT NULL,
            candle_timestamp DATETIME NOT NULL,
            open REAL,
            high REAL,
            low REAL,
            close REAL,
            volume REAL,
            UNIQUE(symbol, timeframe, candle_timestamp)
        );

        -- –¢–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ü–∏–∫–ª–æ–≤
        CREATE TABLE IF NOT EXISTS cycle_results (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            cycle_number INTEGER,
            start_time DATETIME,
            end_time DATETIME,
            symbols_processed INTEGER,
            total_signals INTEGER,
            total_errors INTEGER,
            performance_metrics_json TEXT,
            details_json TEXT
        );

        -- –¢–∞–±–ª–∏—Ü–∞ –æ—à–∏–±–æ–∫
        CREATE TABLE IF NOT EXISTS errors (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
            component TEXT,
            symbol TEXT,
            error_type TEXT,
            error_message TEXT,
            traceback TEXT
        );

        -- –¢–∞–±–ª–∏—Ü–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫
        CREATE TABLE IF NOT EXISTS settings (
            key TEXT PRIMARY KEY,
            value TEXT NOT NULL,
            updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
        );

        -- –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        CREATE INDEX IF NOT EXISTS idx_signals_symbol_time ON signals(symbol, timestamp);
        CREATE INDEX IF NOT EXISTS idx_signals_direction ON signals(direction);
        CREATE INDEX IF NOT EXISTS idx_levels_symbol_timeframe ON levels(symbol, timeframe);
        CREATE INDEX IF NOT EXISTS idx_levels_active ON levels(expires_at) WHERE expires_at IS NULL;
        CREATE INDEX IF NOT EXISTS idx_market_data_lookup ON market_data(symbol, timeframe, candle_timestamp);
        CREATE INDEX IF NOT EXISTS idx_errors_time ON errors(timestamp);
        """
        
        await self._execute_script(create_tables_sql)
    
    @asynccontextmanager
    async def get_connection(self):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î."""
        loop = asyncio.get_running_loop()
        conn = await loop.run_in_executor(None, sqlite3.connect, self.db_path)
        try:
            conn.row_factory = sqlite3.Row
            yield conn
            await loop.run_in_executor(None, conn.commit)
        except Exception as e:
            await loop.run_in_executor(None, conn.rollback)
            raise e
        finally:
            await loop.run_in_executor(None, conn.close)
    
    async def _execute(self, sql: str, params: tuple = ()) -> sqlite3.Cursor:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç SQL –∑–∞–ø—Ä–æ—Å –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫—É—Ä—Å–æ—Ä."""
        self.stats['queries'] += 1
        async with self.get_connection() as conn:
            loop = asyncio.get_running_loop()
            cursor = await loop.run_in_executor(None, conn.execute, sql, params)
            return cursor
    
    async def _execute_script(self, sql: str):
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –º–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–π SQL —Å–∫—Ä–∏–ø—Ç."""
        async with self.get_connection() as conn:
            loop = asyncio.get_running_loop()
            await loop.run_in_executor(None, conn.executescript, sql)
    
    async def _fetch_all(self, sql: str, params: tuple = ()) -> List[sqlite3.Row]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ —Å—Ç—Ä–æ–∫–∏."""
        cursor = await self._execute(sql, params)
        loop = asyncio.get_running_loop()
        rows = await loop.run_in_executor(None, cursor.fetchall)
        return rows
    
    async def _fetch_one(self, sql: str, params: tuple = ()) -> Optional[sqlite3.Row]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É."""
        cursor = await self._execute(sql, params)
        loop = asyncio.get_running_loop()
        row = await loop.run_in_executor(None, cursor.fetchone)
        return row
    
    async def save_signal(self, signal: Union[Dict, Any]) -> int:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–æ—Ä–≥–æ–≤—ã–π —Å–∏–≥–Ω–∞–ª –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            signal: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ —Å–∏–≥–Ω–∞–ª–∞ –∏–ª–∏ –æ–±—ä–µ–∫—Ç Signal
            
        Returns:
            ID —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞ –∏–ª–∏ -1 –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ–±—ä–µ–∫—Ç –≤ —Å–ª–æ–≤–∞—Ä—å, –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
            if hasattr(signal, 'to_dict'):
                signal_dict = signal.to_dict()
            else:
                signal_dict = signal
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ JSON –ø–æ–ª–µ–π
            indicators_json = json.dumps(signal_dict.get('indicators', {}), default=str)
            levels_json = json.dumps(signal_dict.get('levels', {}), default=str)
            confluence_json = json.dumps(signal_dict.get('confluence', {}), default=str)
            metadata_json = json.dumps(signal_dict.get('metadata', {}), default=str)
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–ª–µ–π
            sql = """
                INSERT INTO signals (
                    symbol, signal_type, direction, strength, price, confidence,
                    stop_loss, take_profit, risk_reward_ratio, timeframe,
                    indicators_json, levels_json, confluence_json, description,
                    metadata_json, timestamp
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """
            params = (
                signal_dict.get('symbol'),
                signal_dict.get('type') or signal_dict.get('signal_type'),
                signal_dict.get('direction'),
                signal_dict.get('strength'),
                signal_dict.get('price'),
                signal_dict.get('confidence'),
                signal_dict.get('stop_loss'),
                signal_dict.get('take_profit'),
                signal_dict.get('risk_reward_ratio'),
                signal_dict.get('timeframe', '1h'),
                indicators_json,
                levels_json,
                confluence_json,
                signal_dict.get('description', ''),
                metadata_json,
                signal_dict.get('timestamp', datetime.now().isoformat())
            )
            
            cursor = await self._execute(sql, params)
            signal_id = cursor.lastrowid
            self.stats['signals_saved'] += 1
            logger.debug(f"‚úÖ –°–∏–≥–Ω–∞–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω —Å ID: {signal_id}")
            return signal_id
            
        except Exception as e:
            self.stats['errors'] += 1
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–∏–≥–Ω–∞–ª–∞: {e}")
            logger.error(traceback.format_exc())
            await self.log_error('database', 'save_signal', str(e), traceback.format_exc())
            return -1
    
    async def save_levels(self, symbol: str, timeframe: str, 
                         levels: Dict[str, List]) -> bool:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —É—Ä–æ–≤–Ω–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏/—Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è.
        
        Args:
            symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º
            levels: –°–ª–æ–≤–∞—Ä—å —Å –ø–æ–¥–¥–µ—Ä–∂–∫–∞–º–∏ –∏ —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è–º–∏ (–∫–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç - –æ–±—ä–µ–∫—Ç Level)
            
        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            # –û—Ç–º–µ—á–∞–µ–º —Å—Ç–∞—Ä—ã–µ —É—Ä–æ–≤–Ω–∏ –∫–∞–∫ –∏—Å—Ç–µ–∫—à–∏–µ
            expire_sql = """
                UPDATE levels 
                SET expires_at = datetime('now')
                WHERE symbol = ? AND timeframe = ? AND expires_at IS NULL
            """
            await self._execute(expire_sql, (symbol, timeframe))
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–µ —É—Ä–æ–≤–Ω–∏
            count = 0
            for level_type, level_list in levels.items():
                for level in level_list:
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ–±—ä–µ–∫—Ç Level –≤ —Å–ª–æ–≤–∞—Ä—å, –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
                    if hasattr(level, 'to_dict'):
                        level_dict = level.to_dict()
                    else:
                        level_dict = level
                    
                    metadata_json = json.dumps(level_dict.get('metadata', {}), default=str)
                    
                    sql = """
                        INSERT INTO levels (
                            symbol, timeframe, level_type, price, strength,
                            confidence, touches, volume_profile, calculation_method,
                            cluster_size, first_touch_time, last_touch_time,
                            broken, broken_time, retests, metadata_json
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """
                    params = (
                        symbol,
                        timeframe,
                        level_dict.get('type', level_type),
                        level_dict.get('price'),
                        level_dict.get('strength'),
                        level_dict.get('confidence', 0.5),
                        level_dict.get('touches', 0),
                        level_dict.get('volume_profile', 0.0),
                        level_dict.get('method', level_dict.get('calculation_method', 'unknown')),
                        level_dict.get('cluster_size', 1),
                        level_dict.get('first_touch_time'),
                        level_dict.get('last_touch_time'),
                        level_dict.get('broken', False),
                        level_dict.get('broken_time'),
                        level_dict.get('retests', 0),
                        metadata_json
                    )
                    await self._execute(sql, params)
                    count += 1
            
            self.stats['levels_saved'] += count
            logger.debug(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {count} —É—Ä–æ–≤–Ω–µ–π –¥–ª—è {symbol} {timeframe}")
            return True
            
        except Exception as e:
            self.stats['errors'] += 1
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —É—Ä–æ–≤–Ω–µ–π: {e}")
            await self.log_error('database', 'save_levels', str(e), traceback.format_exc())
            return False
    
    async def get_recent_signals(self, symbol: Optional[str] = None, 
                                 limit: int = 50,
                                 hours: Optional[int] = 24,
                                 min_confidence: float = 0.0) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–∏–≥–Ω–∞–ª—ã.
        
        Args:
            symbol: –§–∏–ª—å—Ç—Ä –ø–æ —Å–∏–º–≤–æ–ª—É
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–≥–Ω–∞–ª–æ–≤
            hours: –ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —á–∞—Å–æ–≤ (–µ—Å–ª–∏ None, —Ç–æ –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è)
            min_confidence: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–∏–≥–Ω–∞–ª–æ–≤ –≤ –≤–∏–¥–µ —Å–ª–æ–≤–∞—Ä–µ–π
        """
        try:
            sql = "SELECT * FROM signals WHERE 1=1"
            params = []
            
            if symbol:
                sql += " AND symbol = ?"
                params.append(symbol)
            
            if hours:
                sql += " AND timestamp > datetime('now', ?)"
                params.append(f'-{hours} hours')
            
            if min_confidence > 0:
                sql += " AND confidence >= ?"
                params.append(min_confidence)
            
            sql += " ORDER BY timestamp DESC LIMIT ?"
            params.append(limit)
            
            rows = await self._fetch_all(sql, tuple(params))
            
            signals = []
            for row in rows:
                signal = dict(row)
                # –ü–∞—Ä—Å–∏–º JSON –ø–æ–ª—è
                for json_field in ['indicators_json', 'levels_json', 'confluence_json', 'metadata_json']:
                    if signal.get(json_field):
                        signal[json_field.replace('_json', '')] = json.loads(signal[json_field])
                    signal.pop(json_field, None)
                signals.append(signal)
            
            return signals
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤: {e}")
            return []
    
    async def get_active_levels(self, symbol: str, timeframe: str) -> Dict[str, List[Dict]]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ –¥–ª—è —Å–∏–º–≤–æ–ª–∞ –∏ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞.
        
        Args:
            symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∫–ª—é—á–∞–º–∏ 'supports' –∏ 'resistances', –∫–∞–∂–¥—ã–π —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
        """
        try:
            sql = """
                SELECT * FROM levels 
                WHERE symbol = ? AND timeframe = ? 
                  AND (expires_at IS NULL OR expires_at > datetime('now'))
                ORDER BY level_type, price
            """
            rows = await self._fetch_all(sql, (symbol, timeframe))
            
            levels = {'supports': [], 'resistances': []}
            for row in rows:
                level = dict(row)
                if level.get('metadata_json'):
                    level['metadata'] = json.loads(level['metadata_json'])
                level.pop('metadata_json', None)
                
                if level['level_type'] == 'support':
                    levels['supports'].append(level)
                else:
                    levels['resistances'].append(level)
            
            return levels
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —É—Ä–æ–≤–Ω–µ–π: {e}")
            return {'supports': [], 'resistances': []}
    
    async def cache_market_data(self, symbol: str, timeframe: str, 
                               df: pd.DataFrame) -> bool:
        """
        –ö–µ—à–∏—Ä—É–µ—Ç —Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.
        
        Args:
            symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º
            df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ open, high, low, close, volume –∏ –∏–Ω–¥–µ–∫—Å–æ–º datetime
            
        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ
        """
        try:
            # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç—Ç–æ–≥–æ —Å–∏–º–≤–æ–ª–∞/—Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ (–æ—Å—Ç–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π)
            cutoff = datetime.now() - timedelta(days=30)
            delete_sql = """
                DELETE FROM market_data 
                WHERE symbol = ? AND timeframe = ? AND candle_timestamp < ?
            """
            await self._execute(delete_sql, (symbol, timeframe, cutoff))
            
            # –í—Å—Ç–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            records = []
            for idx, row in df.iterrows():
                # idx –º–æ–∂–µ—Ç –±—ã—Ç—å Timestamp, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É –¥–ª—è SQLite
                ts = idx.isoformat() if hasattr(idx, 'isoformat') else str(idx)
                records.append((
                    symbol,
                    timeframe,
                    ts,
                    row.get('open'),
                    row.get('high'),
                    row.get('low'),
                    row.get('close'),
                    row.get('volume')
                ))
            
            insert_sql = """
                INSERT OR REPLACE INTO market_data 
                (symbol, timeframe, candle_timestamp, open, high, low, close, volume)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å—Ç–∞–≤–∫—É –±–∞—Ç—á–∞–º–∏
            batch_size = 500
            for i in range(0, len(records), batch_size):
                batch = records[i:i+batch_size]
                async with self.get_connection() as conn:
                    loop = asyncio.get_running_loop()
                    await loop.run_in_executor(None, conn.executemany, insert_sql, batch)
            
            self.stats['market_data_points'] += len(records)
            logger.debug(f"‚úÖ –ó–∞–∫–µ—à–∏—Ä–æ–≤–∞–Ω–æ {len(records)} —Å–≤–µ—á–µ–π –¥–ª—è {symbol} {timeframe}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}")
            return False
    
    async def get_cached_market_data(self, symbol: str, timeframe: str,
                                     limit: int = 1000,
                                     from_date: Optional[datetime] = None,
                                     to_date: Optional[datetime] = None) -> pd.DataFrame:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.
        
        Args:
            symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤–µ—á–µ–π
            from_date: –ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            to_date: –ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
        """
        try:
            sql = """
                SELECT candle_timestamp, open, high, low, close, volume
                FROM market_data
                WHERE symbol = ? AND timeframe = ?
            """
            params = [symbol, timeframe]
            
            if from_date:
                sql += " AND candle_timestamp >= ?"
                params.append(from_date.isoformat())
            if to_date:
                sql += " AND candle_timestamp <= ?"
                params.append(to_date.isoformat())
            
            sql += " ORDER BY candle_timestamp DESC LIMIT ?"
            params.append(limit)
            
            rows = await self._fetch_all(sql, tuple(params))
            
            if not rows:
                return pd.DataFrame()
            
            data = []
            for row in rows:
                data.append({
                    'timestamp': row['candle_timestamp'],
                    'open': row['open'],
                    'high': row['high'],
                    'low': row['low'],
                    'close': row['close'],
                    'volume': row['volume']
                })
            
            df = pd.DataFrame(data)
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            df.set_index('timestamp', inplace=True)
            df.sort_index(inplace=True)
            
            return df
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
            return pd.DataFrame()
    
    async def save_cycle_result(self, result: Dict) -> bool:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ü–∏–∫–ª–∞.
        
        Args:
            result: –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Ü–∏–∫–ª–∞
            
        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ
        """
        try:
            sql = """
                INSERT INTO cycle_results 
                (cycle_number, start_time, end_time, symbols_processed, total_signals, total_errors, performance_metrics_json, details_json)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """
            params = (
                result.get('cycle_number'),
                result.get('start_time'),
                result.get('end_time'),
                result.get('symbols_processed', 0),
                result.get('total_signals', 0),
                result.get('total_errors', 0),
                json.dumps(result.get('performance_metrics', {}), default=str),
                json.dumps(result.get('details', {}), default=str)
            )
            await self._execute(sql, params)
            return True
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Ü–∏–∫–ª–∞: {e}")
            return False
    
    async def log_error(self, component: str, symbol: str, error_type: str, 
                       error_message: str, traceback_str: str = ''):
        """
        –õ–æ–≥–∏—Ä—É–µ—Ç –æ—à–∏–±–∫—É –≤ —Ç–∞–±–ª–∏—Ü—É errors.
        
        Args:
            component: –ö–æ–º–ø–æ–Ω–µ–Ω—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'data_handler', 'levels')
            symbol: –°–∏–º–≤–æ–ª –∏–ª–∏ 'N/A'
            error_type: –¢–∏–ø –æ—à–∏–±–∫–∏
            error_message: –°–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
            traceback_str: –¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞
        """
        try:
            sql = """
                INSERT INTO errors (component, symbol, error_type, error_message, traceback)
                VALUES (?, ?, ?, ?, ?)
            """
            await self._execute(sql, (component, symbol, error_type, error_message, traceback_str))
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–∏ –æ—à–∏–±–∫–∏: {e}")
    
    async def get_statistics(self) -> Dict[str, Any]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–∞–±–æ—Ç—ã –ë–î.
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        try:
            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–≥–Ω–∞–ª–æ–≤ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
            signals_24h = await self._fetch_one("""
                SELECT COUNT(*) as count FROM signals 
                WHERE timestamp > datetime('now', '-1 day')
            """)
            signals_24h = signals_24h['count'] if signals_24h else 0
            
            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—Ä–æ–≤–Ω–µ–π –∞–∫—Ç–∏–≤–Ω—ã—Ö
            levels_active = await self._fetch_one("""
                SELECT COUNT(*) as count FROM levels 
                WHERE expires_at IS NULL OR expires_at > datetime('now')
            """)
            levels_active = levels_active['count'] if levels_active else 0
            
            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
            errors_24h = await self._fetch_one("""
                SELECT COUNT(*) as count FROM errors 
                WHERE timestamp > datetime('now', '-1 day')
            """)
            errors_24h = errors_24h['count'] if errors_24h else 0
            
            # –†–∞–∑–º–µ—Ä –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            db_size = Path(self.db_path).stat().st_size if Path(self.db_path).exists() else 0
            
            return {
                'version': self.VERSION,
                'signals_saved': self.stats['signals_saved'],
                'levels_saved': self.stats['levels_saved'],
                'market_data_points': self.stats['market_data_points'],
                'queries': self.stats['queries'],
                'errors_logged': self.stats['errors'],
                'signals_last_24h': signals_24h,
                'active_levels': levels_active,
                'errors_last_24h': errors_24h,
                'db_size_mb': db_size / (1024 * 1024),
                'db_path': self.db_path
            }
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {}
    
    async def get_setting(self, key: str, default: Any = None) -> Any:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.
        
        Args:
            key: –ö–ª—é—á –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            default: –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –µ—Å–ª–∏ –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω
            
        Returns:
            –ó–Ω–∞—á–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (–¥–µ—Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –∏–∑ JSON)
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–µ—à–∞
            if self.cache_timestamp and datetime.now() - self.cache_timestamp < self.cache_ttl:
                if key in self.settings_cache:
                    return self.settings_cache[key]
            
            sql = "SELECT value FROM settings WHERE key = ?"
            row = await self._fetch_one(sql, (key,))
            
            if row:
                value = json.loads(row['value'])
                # –û–±–Ω–æ–≤–ª—è–µ–º –∫–µ—à
                self.settings_cache[key] = value
                self.cache_timestamp = datetime.now()
                return value
            else:
                return default
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ {key}: {e}")
            return default
    
    async def set_setting(self, key: str, value: Any) -> bool:
        """
        –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.
        
        Args:
            key: –ö–ª—é—á –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            value: –ó–Ω–∞—á–µ–Ω–∏–µ (–±—É–¥–µ—Ç —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–æ –≤ JSON)
            
        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ
        """
        try:
            value_json = json.dumps(value, default=str)
            sql = """
                INSERT OR REPLACE INTO settings (key, value, updated_at)
                VALUES (?, ?, datetime('now'))
            """
            await self._execute(sql, (key, value_json))
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∫–µ—à
            self.settings_cache[key] = value
            self.cache_timestamp = datetime.now()
            
            return True
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ {key}: {e}")
            return False
    
    async def vacuum(self):
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç VACUUM –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö."""
        try:
            await self._execute("VACUUM")
            logger.info("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ (VACUUM)")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ VACUUM: {e}")
    
    async def backup(self, backup_path: Optional[str] = None) -> bool:
        """
        –°–æ–∑–¥–∞–µ—Ç —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            backup_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–ø–∏–∏ (–µ—Å–ª–∏ None, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
            
        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ
        """
        try:
            if not backup_path:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                backup_path = f"data/backups/trading_bot_{timestamp}.db"
            
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –±—ç–∫–∞–ø–æ–≤
            Path(backup_path).parent.mkdir(parents=True, exist_ok=True)
            
            # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª
            import shutil
            loop = asyncio.get_running_loop()
            await loop.run_in_executor(None, shutil.copy2, self.db_path, backup_path)
            
            logger.info(f"‚úÖ –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Å–æ–∑–¥–∞–Ω–∞: {backup_path}")
            return True
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏: {e}")
            return False
    
    async def close(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è (–Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ—Ç, —Ç.–∫. —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –∑–∞–∫—Ä—ã–≤–∞—é—Ç—Å—è –≤ get_connection)."""
        logger.info("üîö DatabaseManager –∑–∞–∫—Ä—ã—Ç")

# ============================================================================
# –°–ò–ù–ì–õ–¢–û–ù –î–õ–Ø –ì–õ–û–ë–ê–õ–¨–ù–û–ì–û –î–û–°–¢–£–ü–ê
# ============================================================================

_db_instance = None

async def get_database() -> DatabaseManager:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä DatabaseManager."""
    global _db_instance
    if _db_instance is None:
        _db_instance = DatabaseManager()
        await _db_instance.initialize()
    return _db_instance

# ============================================================================
# –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï
# ============================================================================

if __name__ == "__main__":
    import asyncio
    
    async def test():
        print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ DatabaseManager...")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ë–î –≤ –ø–∞–º—è—Ç–∏
        db = DatabaseManager(":memory:")
        await db.initialize()
        
        # 1. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–∞
        test_signal = {
            'symbol': 'BTC/USDT',
            'type': 'breakout',
            'direction': 'BUY',
            'strength': 'strong',
            'price': 50000.0,
            'confidence': 0.85,
            'stop_loss': 49500.0,
            'take_profit': 51000.0,
            'risk_reward_ratio': 2.0,
            'timeframe': '1h',
            'indicators': {'rsi': 45, 'macd': 10},
            'levels': {'supports': [49000], 'resistances': [51000]},
            'confluence': {'score': 0.8},
            'description': 'Test signal',
            'timestamp': datetime.now().isoformat()
        }
        
        signal_id = await db.save_signal(test_signal)
        print(f"‚úÖ –°–∏–≥–Ω–∞–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω —Å ID: {signal_id}")
        
        # 2. –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤
        signals = await db.get_recent_signals('BTC/USDT', limit=5)
        print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ —Å–∏–≥–Ω–∞–ª–æ–≤: {len(signals)}")
        if signals:
            print(f"   –ü–µ—Ä–≤—ã–π —Å–∏–≥–Ω–∞–ª: {signals[0]}")
        
        # 3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —É—Ä–æ–≤–Ω–µ–π
        from engine.levels import Level, LevelType, LevelStrength
        test_levels = {
            'supports': [
                Level(price=49000, level_type=LevelType.SUPPORT, strength=LevelStrength.STRONG, confidence=0.9, touches=3),
                Level(price=49500, level_type=LevelType.SUPPORT, strength=LevelStrength.MEDIUM, confidence=0.7, touches=1)
            ],
            'resistances': [
                Level(price=51000, level_type=LevelType.RESISTANCE, strength=LevelStrength.STRONG, confidence=0.9, touches=4),
                Level(price=51500, level_type=LevelType.RESISTANCE, strength=LevelStrength.MEDIUM, confidence=0.6, touches=2)
            ]
        }
        success = await db.save_levels('BTC/USDT', '1h', test_levels)
        print(f"‚úÖ –£—Ä–æ–≤–Ω–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {success}")
        
        # 4. –ü–æ–ª—É—á–µ–Ω–∏–µ —É—Ä–æ–≤–Ω–µ–π
        levels = await db.get_active_levels('BTC/USDT', '1h')
        print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ —É—Ä–æ–≤–Ω–µ–π: {len(levels['supports'])} –ø–æ–¥–¥–µ—Ä–∂–µ–∫, {len(levels['resistances'])} —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏–π")
        
        # 5. –ù–∞—Å—Ç—Ä–æ–π–∫–∏
        await db.set_setting('test_key', {'value': 123})
        value = await db.get_setting('test_key')
        print(f"‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–ª—É—á–µ–Ω–∞: {value}")
        
        # 6. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = await db.get_statistics()
        print(f"‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {stats}")
        
        print("\nüéâ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
    
    asyncio.run(test())
