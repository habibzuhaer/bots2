#!/usr/bin/env python3
"""
–ü–û–õ–ù–´–ô –ú–û–î–£–õ–¨ –ê–ù–ê–õ–ò–ó–ê –ö–û–ù–§–õ–Æ–≠–ù–°–ê
–í–µ—Ä—Å–∏—è: 2.0
–ê–ª–≥–æ—Ä–∏—Ç–º—ã: –ú—É–ª—å—Ç–∏-—Ç–∞–π–º—Ñ—Ä–µ–π–º –∞–Ω–∞–ª–∏–∑, –°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å —Å–∏–≥–Ω–∞–ª–æ–≤, –í–∑–≤–µ—à–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
import logging
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime
import traceback
from collections import defaultdict
import warnings
warnings.filterwarnings('ignore')

logger = logging.getLogger(__name__)

# ============================================================================
# –û–ü–†–ï–î–ï–õ–ï–ù–ò–Ø –ö–õ–ê–°–°–û–í
# ============================================================================

class ConfluenceLevel(Enum):
    """–£—Ä–æ–≤–Ω–∏ –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å–∞."""
    VERY_WEAK = "very_weak"        # 0-20
    WEAK = "weak"                  # 20-40
    MEDIUM = "medium"              # 40-60
    STRONG = "strong"              # 60-80
    VERY_STRONG = "very_strong"    # 80-100

class ConfluenceFactor(Enum):
    """–§–∞–∫—Ç–æ—Ä—ã, –≤–ª–∏—è—é—â–∏–µ –Ω–∞ –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å."""
    MULTI_TIMEFRAME = "multi_timeframe"      # –ú—É–ª—å—Ç–∏-—Ç–∞–π–º—Ñ—Ä–µ–π–º —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å
    VOLUME_PROFILE = "volume_profile"        # –û–±—ä–µ–º–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å
    TECHNICAL_INDICATORS = "technical"       # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
    PATTERN_RECOGNITION = "patterns"         # –ì—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
    PRICE_ACTION = "price_action"            # Price Action
    MARKET_STRUCTURE = "market_structure"    # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä—ã–Ω–∫–∞
    SENTIMENT = "sentiment"                  # –†—ã–Ω–æ—á–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è

@dataclass
class ConfluenceScore:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ü–µ–Ω–∫–∏ –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å–∞."""
    total_score: float  # 0-100
    level: ConfluenceLevel
    factors: Dict[ConfluenceFactor, float]
    timeframes: Dict[str, float]
    details: Dict[str, Any] = field(default_factory=dict)
    timestamp: datetime = field(default_factory=datetime.now)
    
    def to_dict(self) -> Dict:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤ —Å–ª–æ–≤–∞—Ä—å."""
        return {
            'total_score': self.total_score,
            'level': self.level.value,
            'factors': {k.value: v for k, v in self.factors.items()},
            'timeframes': self.timeframes,
            'details': self.details,
            'timestamp': self.timestamp.isoformat()
        }

@dataclass
class ConfluenceAnalysisResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å–∞."""
    symbol: str
    primary_timeframe: str
    timestamp: datetime
    confluence_score: ConfluenceScore
    aligned_levels: Dict[str, List[float]]
    best_entries: List[Dict[str, Any]]
    warnings: List[str] = field(default_factory=list)
    recommendations: List[str] = field(default_factory=list)
    
    def to_dict(self) -> Dict:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤ —Å–ª–æ–≤–∞—Ä—å."""
        return {
            'symbol': self.symbol,
            'primary_timeframe': self.primary_timeframe,
            'timestamp': self.timestamp.isoformat(),
            'confluence_score': self.confluence_score.to_dict(),
            'aligned_levels': self.aligned_levels,
            'best_entries': self.best_entries,
            'warnings': self.warnings,
            'recommendations': self.recommendations
        }

# ============================================================================
# –û–°–ù–û–í–ù–û–ô –ö–õ–ê–°–° CONFLUENCE CALCULATOR
# ============================================================================

class ConfluenceCalculator:
    """
    –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å–∞.
    
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å —Å–∏–≥–Ω–∞–ª–æ–≤ –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –∏–∑–º–µ—Ä–µ–Ω–∏—è–º:
    1. –ú—É–ª—å—Ç–∏-—Ç–∞–π–º—Ñ—Ä–µ–π–º –∞–Ω–∞–ª–∏–∑ (1m, 5m, 15m, 1h, 4h, 1d, 1w)
    2. –†–∞–∑–ª–∏—á–Ω—ã–µ —Ç–∏–ø—ã –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
    3. –û–±—ä–µ–º–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å
    4. –ì—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
    5. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä—ã–Ω–∫–∞
    """
    
    VERSION = "2.0.0"
    
    def __init__(self,
                 min_timeframes: int = 2,
                 weight_timeframes: bool = True,
                 use_volume_profile: bool = True,
                 use_indicators: bool = True,
                 use_patterns: bool = True,
                 use_price_action: bool = True,
                 use_market_structure: bool = True,
                 alignment_threshold: float = 0.7):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä–∞ –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å–∞.
        
        Args:
            min_timeframes: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ –¥–ª—è –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å–∞
            weight_timeframes: –í–∑–≤–µ—à–∏–≤–∞—Ç—å –ø–æ —Å—Ç–∞—Ä—à–∏–Ω—Å—Ç–≤—É —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
            use_volume_profile: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–±—ä–µ–º–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å
            use_indicators: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
            use_patterns: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            use_price_action: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Price Action
            use_market_structure: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ä—ã–Ω–∫–∞
            alignment_threshold: –ü–æ—Ä–æ–≥ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ (0-1)
        """
        
        self.min_timeframes = min_timeframes
        self.weight_timeframes = weight_timeframes
        self.use_volume_profile = use_volume_profile
        self.use_indicators = use_indicators
        self.use_patterns = use_patterns
        self.use_price_action = use_price_action
        self.use_market_structure = use_market_structure
        self.alignment_threshold = alignment_threshold
        
        # –í–µ—Å–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
        self.timeframe_weights = {
            '1m': 1.0,
            '5m': 1.2,
            '15m': 1.5,
            '30m': 1.8,
            '1h': 2.0,
            '2h': 2.2,
            '4h': 2.5,
            '6h': 2.7,
            '8h': 2.8,
            '12h': 2.9,
            '1d': 3.0,
            '3d': 3.2,
            '1w': 3.5,
            '1M': 4.0
        }
        
        # –í–µ—Å–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤
        self.factor_weights = {
            ConfluenceFactor.MULTI_TIMEFRAME: 0.25,
            ConfluenceFactor.VOLUME_PROFILE: 0.15,
            ConfluenceFactor.TECHNICAL_INDICATORS: 0.20,
            ConfluenceFactor.PATTERN_RECOGNITION: 0.10,
            ConfluenceFactor.PRICE_ACTION: 0.15,
            ConfluenceFactor.MARKET_STRUCTURE: 0.10,
            ConfluenceFactor.SENTIMENT: 0.05
        }
        
        # –ü–æ—Ä–æ–≥–∏ –¥–ª—è —É—Ä–æ–≤–Ω–µ–π –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å–∞
        self.level_thresholds = {
            ConfluenceLevel.VERY_WEAK: (0, 20),
            ConfluenceLevel.WEAK: (20, 40),
            ConfluenceLevel.MEDIUM: (40, 60),
            ConfluenceLevel.STRONG: (60, 80),
            ConfluenceLevel.VERY_STRONG: (80, 100)
        }
        
        # –ö–µ—à —Ä–∞—Å—á–µ—Ç–æ–≤
        self.cache = {}
        self.cache_max_size = 100
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'total_analyses': 0,
            'cache_hits': 0,
            'average_scores': [],
            'errors': []
        }
        
        logger.info(f"‚úÖ ConfluenceCalculator v{self.VERSION} –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        logger.info(f"   –ú–∏–Ω–∏–º—É–º —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤: {min_timeframes}")
        logger.info(f"   –í–∑–≤–µ—à–∏–≤–∞–Ω–∏–µ –¢–§: {weight_timeframes}")
        logger.info(f"   –ü–æ—Ä–æ–≥ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏: {alignment_threshold}")
    
    def analyze(self, data_frames: Dict[str, pd.DataFrame],
                symbol: str = "UNKNOWN",
                primary_timeframe: str = "1h") -> ConfluenceAnalysisResult:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å–∞.
        
        Args:
            data_frames: –°–ª–æ–≤–∞—Ä—å {—Ç–∞–π–º—Ñ—Ä–µ–π–º: DataFrame} —Å –¥–∞–Ω–Ω—ã–º–∏
            symbol: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å–∏–º–≤–æ–ª–∞
            primary_timeframe: –û—Å–Ω–æ–≤–Ω–æ–π —Ç–∞–π–º—Ñ—Ä–µ–π–º –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            ConfluenceAnalysisResult —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        """
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if not data_frames or len(data_frames) < self.min_timeframes:
            logger.warning(f"‚ö†Ô∏è  –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤: {len(data_frames)}, —Ç—Ä–µ–±—É–µ—Ç—Å—è {self.min_timeframes}")
            return self._create_empty_result(symbol, primary_timeframe)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª—é—á–∞ –∫–µ—à–∞
        cache_key = f"{symbol}_{len(data_frames)}_{max(len(df) for df in data_frames.values())}"
        
        if cache_key in self.cache:
            self.stats['cache_hits'] += 1
            logger.debug(f"üéØ –ö–µ—à –ø–æ–ø–∞–¥–∞–Ω–∏–µ –¥–ª—è {symbol}")
            return self.cache[cache_key]
        
        self.stats['total_analyses'] += 1
        
        logger.info(f"üßÆ –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å–∞ –¥–ª—è {symbol} ({len(data_frames)} —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤)")
        start_time = datetime.now()
        
        try:
            # 1. –†–∞—Å—á–µ—Ç —Ñ–∞–∫—Ç–æ—Ä–æ–≤ –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å–∞
            factor_scores = self._calculate_factor_scores(data_frames, primary_timeframe)
            
            # 2. –†–∞—Å—á–µ—Ç —Ç–∞–π–º—Ñ—Ä–µ–π–º —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏
            timeframe_scores = self._calculate_timeframe_alignment(data_frames)
            
            # 3. –û–±—â–∏–π —Å—á–µ—Ç –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å–∞
            total_score = self._calculate_total_score(factor_scores, timeframe_scores)
            
            # 4. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å–∞
            level = self._determine_confluence_level(total_score)
            
            # 5. –ü–æ–∏—Å–∫ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω—ã—Ö —É—Ä–æ–≤–Ω–µ–π
            aligned_levels = self._find_aligned_levels(data_frames)
            
            # 6. –õ—É—á—à–∏–µ —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞
            best_entries = self._find_best_entries(data_frames, aligned_levels)
            
            # 7. –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            warnings = self._generate_warnings(factor_scores, timeframe_scores)
            recommendations = self._generate_recommendations(total_score, aligned_levels, best_entries)
            
            # 8. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            result = ConfluenceAnalysisResult(
                symbol=symbol,
                primary_timeframe=primary_timeframe,
                timestamp=datetime.now(),
                confluence_score=ConfluenceScore(
                    total_score=total_score,
                    level=level,
                    factors=factor_scores,
                    timeframes=timeframe_scores,
                    details={
                        'processing_time': (datetime.now() - start_time).total_seconds(),
                        'data_points': sum(len(df) for df in data_frames.values())
                    }
                ),
                aligned_levels=aligned_levels,
                best_entries=best_entries,
                warnings=warnings,
                recommendations=recommendations
            )
            
            # 9. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            self.stats['average_scores'].append(total_score)
            
            # 10. –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            self._log_results(result)
            
            # 11. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∫–µ—à
            self.cache[cache_key] = result
            self._clean_cache()
            
            return result
            
        except Exception as e:
            error_msg = f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å–∞ –¥–ª—è {symbol}: {e}"
            logger.error(error_msg)
            logger.error(traceback.format_exc())
            
            self.stats['errors'].append({
                'timestamp': datetime.now().isoformat(),
                'symbol': symbol,
                'error': str(e)
            })
            
            return self._create_empty_result(symbol, primary_timeframe)
    
    def _calculate_factor_scores(self, data_frames: Dict[str, pd.DataFrame],
                                primary_timeframe: str) -> Dict[ConfluenceFactor, float]:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ—Ü–µ–Ω–∫–∏ –ø–æ –∫–∞–∂–¥–æ–º—É —Ñ–∞–∫—Ç–æ—Ä—É –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å–∞."""
        factor_scores = {}
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
        primary_df = data_frames.get(primary_timeframe)
        if primary_df is None:
            primary_df = list(data_frames.values())[0]
        
        # 1. –ú—É–ª—å—Ç–∏-—Ç–∞–π–º—Ñ—Ä–µ–π–º —Ñ–∞–∫—Ç–æ—Ä (—Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ)
        mtf_score = self._calculate_mtf_factor(data_frames, primary_df)
        factor_scores[ConfluenceFactor.MULTI_TIMEFRAME] = mtf_score
        
        # 2. –û–±—ä–µ–º–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å
        if self.use_volume_profile:
            volume_score = self._calculate_volume_profile_factor(primary_df, data_frames)
            factor_scores[ConfluenceFactor.VOLUME_PROFILE] = volume_score
        
        # 3. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        if self.use_indicators:
            technical_score = self._calculate_technical_factor(primary_df, data_frames)
            factor_scores[ConfluenceFactor.TECHNICAL_INDICATORS] = technical_score
        
        # 4. –ì—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        if self.use_patterns:
            pattern_score = self._calculate_pattern_factor(primary_df, data_frames)
            factor_scores[ConfluenceFactor.PATTERN_RECOGNITION] = pattern_score
        
        # 5. Price Action
        if self.use_price_action:
            pa_score = self._calculate_price_action_factor(primary_df, data_frames)
            factor_scores[ConfluenceFactor.PRICE_ACTION] = pa_score
        
        # 6. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä—ã–Ω–∫–∞
        if self.use_market_structure:
            structure_score = self._calculate_market_structure_factor(primary_df, data_frames)
            factor_scores[ConfluenceFactor.MARKET_STRUCTURE] = structure_score
        
        # 7. –°–µ–Ω—Ç–∏–º–µ–Ω—Ç (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
        sentiment_score = self._calculate_sentiment_factor()
        if sentiment_score > 0:
            factor_scores[ConfluenceFactor.SENTIMENT] = sentiment_score
        
        return factor_scores
    
    def _calculate_mtf_factor(self, data_frames: Dict[str, pd.DataFrame],
                             primary_df: pd.DataFrame) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –º—É–ª—å—Ç–∏-—Ç–∞–π–º—Ñ—Ä–µ–π–º —Ñ–∞–∫—Ç–æ—Ä."""
        if len(data_frames) < 2:
            return 0.0
        
        try:
            current_price = primary_df['close'].iloc[-1]
            alignments = []
            
            for tf, df in data_frames.items():
                if df is primary_df:
                    continue
                
                if len(df) < 20:
                    continue
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç—Ä–µ–Ω–¥ –Ω–∞ –∫–∞–∂–¥–æ–º —Ç–∞–π–º—Ñ—Ä–µ–π–º–µ
                df_trend = self._determine_trend(df)
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —É—Ä–æ–≤–Ω–∏
                df_support, df_resistance = self._find_key_levels(df)
                
                # –û—Ü–µ–Ω–∏–≤–∞–µ–º —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å —Å –æ—Å–Ω–æ–≤–Ω—ã–º –¢–§
                if df_trend == self._determine_trend(primary_df):
                    # –¢—Ä–µ–Ω–¥—ã —Å–æ–≤–ø–∞–¥–∞—é—Ç
                    alignments.append(1.0)
                else:
                    # –¢—Ä–µ–Ω–¥—ã —Ä–∞—Å—Ö–æ–¥—è—Ç—Å—è
                    alignments.append(0.0)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–ª–∏–∑–æ—Å—Ç—å –∫ —É—Ä–æ–≤–Ω—è–º
                price_to_support = abs(current_price - df_support) / current_price if df_support else 1.0
                price_to_resistance = abs(df_resistance - current_price) / current_price if df_resistance else 1.0
                
                if price_to_support < 0.01 or price_to_resistance < 0.01:
                    # –¶–µ–Ω–∞ –±–ª–∏–∑–∫–∞ –∫ —É—Ä–æ–≤–Ω—é –Ω–∞ –¥—Ä—É–≥–æ–º –¢–§
                    alignments[-1] += 0.5
            
            if not alignments:
                return 0.0
            
            # –°—Ä–µ–¥–Ω—è—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å —Å –≤–µ—Å–∞–º–∏
            avg_alignment = np.mean(alignments)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ 0-100
            mtf_score = min(avg_alignment * 70, 100)
            
            # –ë–æ–Ω—É—Å –∑–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
            timeframe_bonus = min(len(data_frames) * 5, 30)
            mtf_score = min(mtf_score + timeframe_bonus, 100)
            
            return mtf_score
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ MTF —Ñ–∞–∫—Ç–æ—Ä–∞: {e}")
            return 0.0
    
    def _calculate_volume_profile_factor(self, primary_df: pd.DataFrame,
                                        data_frames: Dict[str, pd.DataFrame]) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ñ–∞–∫—Ç–æ—Ä –æ–±—ä–µ–º–Ω–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è."""
        try:
            if len(primary_df) < 50:
                return 0.0
            
            current_price = primary_df['close'].iloc[-1]
            
            # –°–æ–∑–¥–∞–µ–º Volume Profile –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –¢–§
            volume_levels = self._create_volume_profile(primary_df)
            
            if not volume_levels:
                return 0.0
            
            # –ù–∞—Ö–æ–¥–∏–º POC (Point of Control)
            poc_price = max(volume_levels, key=volume_levels.get)
            poc_volume = volume_levels[poc_price]
            
            # –û—Ü–µ–Ω–∏–≤–∞–µ–º –ø–æ–ª–æ–∂–µ–Ω–∏–µ —Ü–µ–Ω—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ POC
            price_distance = abs(current_price - poc_price) / current_price
            
            # –ß–µ–º –±–ª–∏–∂–µ —Ü–µ–Ω–∞ –∫ POC, —Ç–µ–º –≤—ã—à–µ –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å
            if price_distance < 0.01:
                poc_score = 90
            elif price_distance < 0.02:
                poc_score = 70
            elif price_distance < 0.03:
                poc_score = 50
            elif price_distance < 0.05:
                poc_score = 30
            else:
                poc_score = 10
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ä–µ–º–Ω—É—é –ø–æ–¥–¥–µ—Ä–∂–∫—É –Ω–∞ –¥—Ä—É–≥–∏—Ö –¢–§
            volume_consensus = 0
            for tf, df in data_frames.items():
                if df is primary_df:
                    continue
                
                if len(df) < 30:
                    continue
                
                tf_volume_levels = self._create_volume_profile(df)
                if tf_volume_levels:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –ø–∏–∫ –æ–±—ä–µ–º–∞ –æ–∫–æ–ª–æ —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω—ã
                    for price, volume in tf_volume_levels.items():
                        if abs(price - current_price) / current_price < 0.01:
                            volume_consensus += 1
                            break
            
            # –ë–æ–Ω—É—Å –∑–∞ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –ø–æ –æ–±—ä–µ–º–∞–º
            consensus_bonus = min(volume_consensus * 10, 30)
            
            total_score = poc_score + consensus_bonus
            
            return min(total_score, 100)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ Volume Profile —Ñ–∞–∫—Ç–æ—Ä–∞: {e}")
            return 0.0
    
    def _create_volume_profile(self, df: pd.DataFrame, num_levels: int = 50) -> Dict[float, float]:
        """–°–æ–∑–¥–∞–µ—Ç –æ–±—ä–µ–º–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å –¥–ª—è DataFrame."""
        volume_profile = {}
        
        try:
            price_min = df['low'].min()
            price_max = df['high'].max()
            price_step = (price_max - price_min) / num_levels
            
            for i in range(num_levels):
                level_low = price_min + i * price_step
                level_high = level_low + price_step
                level_mid = (level_low + level_high) / 2
                
                volume_at_level = 0
                
                for _, row in df.iterrows():
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–µ—Ä–µ–∫—Ä—ã–≤–∞–µ—Ç—Å—è –ª–∏ —Å–≤–µ—á–∞ —Å —É—Ä–æ–≤–Ω–µ–º
                    if row['high'] >= level_low and row['low'] <= level_high:
                        # –ü—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—ä–µ–º–∞
                        overlap = min(row['high'], level_high) - max(row['low'], level_low)
                        candle_range = row['high'] - row['low']
                        if candle_range > 0:
                            volume_at_level += row['volume'] * (overlap / candle_range)
                
                if volume_at_level > 0:
                    volume_profile[level_mid] = volume_at_level
            
            return volume_profile
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è Volume Profile: {e}")
            return {}
    
    def _calculate_technical_factor(self, primary_df: pd.DataFrame,
                                   data_frames: Dict[str, pd.DataFrame]) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ñ–∞–∫—Ç–æ—Ä —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤."""
        try:
            if len(primary_df) < 50:
                return 0.0
            
            current_price = primary_df['close'].iloc[-1]
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –¢–§
            rsi = self._calculate_rsi(primary_df['close'])
            macd, signal = self._calculate_macd(primary_df['close'])
            bb_upper, bb_lower = self._calculate_bollinger_bands(primary_df['close'])
            
            # –û—Ü–µ–Ω–∫–∞ RSI
            rsi_score = 0
            if rsi < 30:
                rsi_score = 80  # –ü–µ—Ä–µ–ø—Ä–æ–¥–∞–Ω–Ω–æ—Å—Ç—å, –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª —Ä–æ—Å—Ç–∞
            elif rsi > 70:
                rsi_score = 80  # –ü–µ—Ä–µ–∫—É–ø–ª–µ–Ω–Ω–æ—Å—Ç—å, –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –ø–∞–¥–µ–Ω–∏—è
            elif 40 <= rsi <= 60:
                rsi_score = 50  # –ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ
            
            # –û—Ü–µ–Ω–∫–∞ MACD
            macd_score = 0
            if macd > signal:
                macd_score = 70  # –ë—ã—á–∏–π —Å–∏–≥–Ω–∞–ª
            elif macd < signal:
                macd_score = 70  # –ú–µ–¥–≤–µ–∂–∏–π —Å–∏–≥–Ω–∞–ª
            else:
                macd_score = 50  # –ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ
            
            # –û—Ü–µ–Ω–∫–∞ Bollinger Bands
            bb_score = 0
            if current_price <= bb_lower:
                bb_score = 80  # –ù–∏–∂–Ω—è—è –ø–æ–ª–æ—Å–∞
            elif current_price >= bb_upper:
                bb_score = 80  # –í–µ—Ä—Ö–Ω—è—è –ø–æ–ª–æ—Å–∞
            elif bb_lower < current_price < bb_upper:
                bb_score = 50  # –í–Ω—É—Ç—Ä–∏ –∫–∞–Ω–∞–ª–∞
            
            # –£—Å—Ä–µ–¥–Ω—è–µ–º —Å –≤–µ—Å–∞–º–∏
            technical_score = (rsi_score * 0.3 + macd_score * 0.4 + bb_score * 0.3)
            
            return technical_score
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ Technical —Ñ–∞–∫—Ç–æ—Ä–∞: {e}")
            return 0.0
    
    def _calculate_pattern_factor(self, primary_df: pd.DataFrame,
                                 data_frames: Dict[str, pd.DataFrame]) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ñ–∞–∫—Ç–æ—Ä –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤."""
        try:
            if len(primary_df) < 50:
                return 0.0
            
            # –ü–æ–∏—Å–∫ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–º –¢–§
            patterns_primary = self._detect_patterns(primary_df)
            
            # –ü–æ–∏—Å–∫ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –Ω–∞ –¥—Ä—É–≥–∏—Ö –¢–§
            patterns_total = len(patterns_primary)
            
            for tf, df in data_frames.items():
                if tf == "1h":  # –£–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–ª–∏
                    continue
                
                if len(df) >= 50:
                    patterns_other = self._detect_patterns(df)
                    patterns_total += len(patterns_other)
            
            # –ß–µ–º –±–æ–ª—å—à–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤, —Ç–µ–º –≤—ã—à–µ –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å
            # –ù–æ –Ω–µ –±–æ–ª–µ–µ 10 –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —Å—á–µ—Ç–∞
            pattern_score = min(patterns_total * 10, 100)
            
            return pattern_score
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ Pattern —Ñ–∞–∫—Ç–æ—Ä–∞: {e}")
            return 0.0
    
    def _detect_patterns(self, df: pd.DataFrame) -> List[str]:
        """–û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ DataFrame."""
        patterns = []
        
        try:
            closes = df['close'].values[-30:]
            highs = df['high'].values[-30:]
            lows = df['low'].values[-30:]
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ Doji
            if len(closes) >= 1:
                body = abs(closes[-1] - df['open'].iloc[-1])
                range_price = highs[-1] - lows[-1]
                if range_price > 0 and body / range_price < 0.1:
                    patterns.append("doji")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ Hammer/Shooting Star
            if len(closes) >= 2:
                body = abs(closes[-1] - df['open'].iloc[-1])
                lower_shadow = min(df['open'].iloc[-1], closes[-1]) - lows[-1]
                upper_shadow = highs[-1] - max(df['open'].iloc[-1], closes[-1])
                
                if lower_shadow > body * 2 and upper_shadow < body * 0.5:
                    patterns.append("hammer")
                elif upper_shadow > body * 2 and lower_shadow < body * 0.5:
                    patterns.append("shooting_star")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ Engulfing
            if len(closes) >= 2:
                if closes[-2] < df['open'].iloc[-2] and closes[-1] > df['open'].iloc[-1]:
                    if closes[-1] > df['open'].iloc[-2] and df['open'].iloc[-1] < closes[-2]:
                        patterns.append("bullish_engulfing")
                
                if closes[-2] > df['open'].iloc[-2] and closes[-1] < df['open'].iloc[-1]:
                    if closes[-1] < df['open'].iloc[-2] and df['open'].iloc[-1] > closes[-2]:
                        patterns.append("bearish_engulfing")
            
            # –ü—Ä–æ—Å—Ç—ã–µ —Ç—Ä–µ–Ω–¥–æ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            if len(closes) >= 10:
                # –í–æ—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥
                if closes[-1] > closes[-5] > closes[-10]:
                    patterns.append("uptrend")
                
                # –ù–∏—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥
                if closes[-1] < closes[-5] < closes[-10]:
                    patterns.append("downtrend")
                
                # –§–ª—ç—Ç
                high_10 = max(highs[-10:])
                low_10 = min(lows[-10:])
                if (high_10 - low_10) / low_10 < 0.05:
                    patterns.append("consolidation")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {e}")
        
        return patterns
    
    def _calculate_price_action_factor(self, primary_df: pd.DataFrame,
                                      data_frames: Dict[str, pd.DataFrame]) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ñ–∞–∫—Ç–æ—Ä Price Action."""
        try:
            if len(primary_df) < 20:
                return 0.0
            
            current_price = primary_df['close'].iloc[-1]
            
            # –ê–Ω–∞–ª–∏–∑ —Å–≤–µ—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–º –¢–§
            candle_score = 0
            
            # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å–≤–µ—á–µ–π
            for i in range(1, 6):
                if len(primary_df) <= i:
                    break
                
                idx = -i
                
                # –ë—ã—á—å—è —Å–≤–µ—á–∞
                if primary_df['close'].iloc[idx] > primary_df['open'].iloc[idx]:
                    candle_score += 2
                
                # –ú–µ–¥–≤–µ–∂—å—è —Å–≤–µ—á–∞
                else:
                    candle_score -= 2
                
                # –î–ª–∏–Ω–Ω–∞—è —Å–≤–µ—á–∞ (–±–æ–ª—å—à–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω)
                candle_range = (primary_df['high'].iloc[idx] - primary_df['low'].iloc[idx]) / current_price
                if candle_range > 0.02:
                    if primary_df['close'].iloc[idx] > primary_df['open'].iloc[idx]:
                        candle_score += 3  # –°–∏–ª—å–Ω–∞—è –±—ã—á—å—è —Å–≤–µ—á–∞
                    else:
                        candle_score -= 3  # –°–∏–ª—å–Ω–∞—è –º–µ–¥–≤–µ–∂—å—è —Å–≤–µ—á–∞
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å—á–µ—Ç
            max_possible_score = 5 * 5  # 5 —Å–≤–µ—á–µ–π * –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–ª 5
            candle_score_normalized = (candle_score + max_possible_score) / (2 * max_possible_score) * 100
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–∞–∑—Ä—ã–≤—ã (–≥—ç–ø—ã)
            gap_score = 0
            if len(primary_df) >= 2:
                prev_close = primary_df['close'].iloc[-2]
                current_open = primary_df['open'].iloc[-1]
                
                gap_up = (current_open - prev_close) / prev_close
                gap_down = (prev_close - current_open) / prev_close
                
                if gap_up > 0.01:
                    gap_score = 70  # –ì—ç–ø –≤–≤–µ—Ä—Ö
                elif gap_down > 0.01:
                    gap_score = 70  # –ì—ç–ø –≤–Ω–∏–∑
                else:
                    gap_score = 50  # –ë–µ–∑ –≥—ç–ø–∞
            
            # –£—Å—Ä–µ–¥–Ω—è–µ–º
            pa_score = (candle_score_normalized * 0.7 + gap_score * 0.3)
            
            return pa_score
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ Price Action —Ñ–∞–∫—Ç–æ—Ä–∞: {e}")
            return 0.0
    
    def _calculate_market_structure_factor(self, primary_df: pd.DataFrame,
                                          data_frames: Dict[str, pd.DataFrame]) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ñ–∞–∫—Ç–æ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ä—ã–Ω–∫–∞."""
        try:
            if len(primary_df) < 50:
                return 0.0
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–º –¢–§
            structure_score = 0
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç—Ä–µ–Ω–¥
            trend = self._determine_trend(primary_df)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —É—Ä–æ–≤–Ω–∏
            support, resistance = self._find_key_levels(primary_df)
            
            current_price = primary_df['close'].iloc[-1]
            
            # –û—Ü–µ–Ω–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            if trend in ["strong_bullish", "bullish"]:
                structure_score += 40
            elif trend in ["strong_bearish", "bearish"]:
                structure_score += 40
            else:
                structure_score += 20
            
            # –û—Ü–µ–Ω–∫–∞ –ø–æ–ª–æ–∂–µ–Ω–∏—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —É—Ä–æ–≤–Ω–µ–π
            if support and current_price > support:
                distance_to_support = (current_price - support) / current_price
                if distance_to_support < 0.02:
                    structure_score += 30  # –£ –ø–æ–¥–¥–µ—Ä–∂–∫–∏
                elif distance_to_support < 0.05:
                    structure_score += 20  # –ë–ª–∏–∑–∫–æ –∫ –ø–æ–¥–¥–µ—Ä–∂–∫–µ
            
            if resistance and current_price < resistance:
                distance_to_resistance = (resistance - current_price) / current_price
                if distance_to_resistance < 0.02:
                    structure_score += 30  # –£ —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è
                elif distance_to_resistance < 0.05:
                    structure_score += 20  # –ë–ª–∏–∑–∫–æ –∫ —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—é
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –Ω–∞ –¥—Ä—É–≥–∏—Ö –¢–§
            tf_agreement = 0
            for tf, df in data_frames.items():
                if df is primary_df:
                    continue
                
                if len(df) >= 50:
                    tf_trend = self._determine_trend(df)
                    if (trend in ["bullish", "strong_bullish"] and 
                        tf_trend in ["bullish", "strong_bullish"]):
                        tf_agreement += 1
                    elif (trend in ["bearish", "strong_bearish"] and 
                          tf_trend in ["bearish", "strong_bearish"]):
                        tf_agreement += 1
                    elif trend == "ranging" and tf_trend == "ranging":
                        tf_agreement += 1
            
            structure_score += min(tf_agreement * 10, 30)
            
            return min(structure_score, 100)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ Market Structure —Ñ–∞–∫—Ç–æ—Ä–∞: {e}")
            return 0.0
    
    def _calculate_sentiment_factor(self) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ñ–∞–∫—Ç–æ—Ä —Ä—ã–Ω–æ—á–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π."""
        # –í —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ –∑–¥–µ—Å—å –±—É–¥–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å API —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç–∞
        # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        return 50.0
    
    def _calculate_timeframe_alignment(self, data_frames: Dict[str, pd.DataFrame]) -> Dict[str, float]:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –ø–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º."""
        timeframe_scores = {}
        
        try:
            for tf, df in data_frames.items():
                if len(df) < 20:
                    timeframe_scores[tf] = 0.0
                    continue
                
                # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Ç—Ä–µ–Ω–¥–∞ –Ω–∞ –∫–∞–∂–¥–æ–º –¢–§
                trend_strength = self._calculate_trend_strength(df)
                
                # –û—Ü–µ–Ω–∏–≤–∞–µ–º –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
                volatility = self._calculate_volatility(df)
                
                # –û—Ü–µ–Ω–∏–≤–∞–µ–º —á–µ—Ç–∫–æ—Å—Ç—å —É—Ä–æ–≤–Ω–µ–π
                level_clarity = self._calculate_level_clarity(df)
                
                # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
                tf_score = (trend_strength * 0.4 + volatility * 0.3 + level_clarity * 0.3)
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤–µ—Å —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
                if self.weight_timeframes:
                    weight = self.timeframe_weights.get(tf, 1.0)
                    tf_score = min(tf_score * weight / 2, 100)
                
                timeframe_scores[tf] = tf_score
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ —Ç–∞–π–º—Ñ—Ä–µ–π–º —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏: {e}")
        
        return timeframe_scores
    
    def _calculate_trend_strength(self, df: pd.DataFrame) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å–∏–ª—É —Ç—Ä–µ–Ω–¥–∞."""
        try:
            closes = df['close'].values[-20:]
            
            if len(closes) < 5:
                return 50.0
            
            # –õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–∞–∫–ª–æ–Ω–∞
            x = np.arange(len(closes))
            slope, _, r_value, _, _ = np.polyfit(x, closes, 1, full=False)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∫–ª–æ–Ω
            slope_normalized = abs(slope) / np.mean(closes) * 1000
            
            # R-squared –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–∏–ª—É —Ç—Ä–µ–Ω–¥–∞
            r_squared = r_value ** 2 if r_value is not None else 0
            
            # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º
            strength = (min(slope_normalized, 50) * 0.5 + r_squared * 50)
            
            return min(strength, 100)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ —Å–∏–ª—ã —Ç—Ä–µ–Ω–¥–∞: {e}")
            return 50.0
    
    def _calculate_volatility(self, df: pd.DataFrame) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å."""
        try:
            closes = df['close'].values[-20:]
            
            if len(closes) < 5:
                return 50.0
            
            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π
            returns = np.diff(closes) / closes[:-1]
            volatility = np.std(returns) * 100  # –í –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ 0-100
            # –í—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å = 100, –Ω–∏–∑–∫–∞—è = 0
            volatility_score = min(volatility * 10, 100)
            
            return volatility_score
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏: {e}")
            return 50.0
    
    def _calculate_level_clarity(self, df: pd.DataFrame) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —á–µ—Ç–∫–æ—Å—Ç—å —É—Ä–æ–≤–Ω–µ–π."""
        try:
            if len(df) < 30:
                return 50.0
            
            highs = df['high'].values[-30:]
            lows = df['low'].values[-30:]
            
            # –ò—â–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —É—Ä–æ–≤–Ω–∏
            level_counts = defaultdict(int)
            
            for high in highs:
                # –û–∫—Ä—É–≥–ª—è–µ–º –¥–æ 2 –∑–Ω–∞–∫–æ–≤
                level = round(high, 2)
                level_counts[level] += 1
            
            for low in lows:
                level = round(low, 2)
                level_counts[level] += 1
            
            if not level_counts:
                return 50.0
            
            # –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞—Å–∞–Ω–∏–π
            max_touches = max(level_counts.values())
            
            # –ß–µ–º –±–æ–ª—å—à–µ –∫–∞—Å–∞–Ω–∏–π —É—Ä–æ–≤–Ω—è, —Ç–µ–º –≤—ã—à–µ —á–µ—Ç–∫–æ—Å—Ç—å
            clarity = min(max_touches * 10, 100)
            
            return clarity
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ —á–µ—Ç–∫–æ—Å—Ç–∏ —É—Ä–æ–≤–Ω–µ–π: {e}")
            return 50.0
    
    def _calculate_total_score(self, factor_scores: Dict[ConfluenceFactor, float],
                              timeframe_scores: Dict[str, float]) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ–±—â–∏–π —Å—á–µ—Ç –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å–∞."""
        # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞ —Ñ–∞–∫—Ç–æ—Ä–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫
        factor_total = 0
        total_weight = 0
        
        for factor, score in factor_scores.items():
            weight = self.factor_weights.get(factor, 0)
            factor_total += score * weight
            total_weight += weight
        
        factor_weighted = factor_total / total_weight if total_weight > 0 else 0
        
        # –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –ø–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º
        tf_avg = np.mean(list(timeframe_scores.values())) if timeframe_scores else 0
        
        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º
        total_score = (factor_weighted * 0.7 + tf_avg * 0.3)
        
        return min(max(total_score, 0), 100)
    
    def _determine_confluence_level(self, score: float) -> ConfluenceLevel:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —É—Ä–æ–≤–µ–Ω—å –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å–∞ –ø–æ —Å—á–µ—Ç—É."""
        for level, (low, high) in self.level_thresholds.items():
            if low <= score < high:
                return level
        
        return ConfluenceLevel.MEDIUM  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    def _find_aligned_levels(self, data_frames: Dict[str, pd.DataFrame]) -> Dict[str, List[float]]:
        """–ù–∞—Ö–æ–¥–∏—Ç —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ –Ω–∞ –≤—Å–µ—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞—Ö."""
        aligned_levels = {
            'supports': [],
            'resistances': []
        }
        
        try:
            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —É—Ä–æ–≤–Ω–∏
            all_supports = []
            all_resistances = []
            
            for tf, df in data_frames.items():
                if len(df) < 20:
                    continue
                
                support, resistance = self._find_key_levels(df)
                
                if support:
                    all_supports.append(support)
                if resistance:
                    all_resistances.append(resistance)
            
            # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑—É–µ–º —É—Ä–æ–≤–Ω–∏
            if all_supports:
                clustered_supports = self._cluster_levels(all_supports)
                aligned_levels['supports'] = [float(level) for level in clustered_supports]
            
            if all_resistances:
                clustered_resistances = self._cluster_levels(all_resistances)
                aligned_levels['resistances'] = [float(level) for level in clustered_resistances]
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω—ã—Ö —É—Ä–æ–≤–Ω–µ–π: {e}")
        
        return aligned_levels
    
    def _find_key_levels(self, df: pd.DataFrame) -> Tuple[Optional[float], Optional[float]]:
        """–ù–∞—Ö–æ–¥–∏—Ç –∫–ª—é—á–µ–≤—ã–µ —É—Ä–æ–≤–Ω–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∏ —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è."""
        try:
            if len(df) < 20:
                return None, None
            
            highs = df['high'].values[-20:]
            lows = df['low'].values[-20:]
            current_price = df['close'].iloc[-1]
            
            # –ü–æ–∏—Å–∫ –∫–ª—é—á–µ–≤–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏
            support_candidates = []
            for low in lows:
                if low < current_price:
                    support_candidates.append(low)
            
            support = max(support_candidates) if support_candidates else None
            
            # –ü–æ–∏—Å–∫ –∫–ª—é—á–µ–≤–æ–≥–æ —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è
            resistance_candidates = []
            for high in highs:
                if high > current_price:
                    resistance_candidates.append(high)
            
            resistance = min(resistance_candidates) if resistance_candidates else None
            
            return support, resistance
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö —É—Ä–æ–≤–Ω–µ–π: {e}")
            return None, None
    
    def _cluster_levels(self, levels: List[float], threshold: float = 0.01) -> List[float]:
        """–ö–ª–∞—Å—Ç–µ—Ä–∏–∑—É–µ—Ç –±–ª–∏–∑–∫–∏–µ —É—Ä–æ–≤–Ω–∏."""
        if not levels:
            return []
        
        levels_sorted = sorted(levels)
        clusters = []
        current_cluster = [levels_sorted[0]]
        
        for level in levels_sorted[1:]:
            if abs(level - current_cluster[-1]) / current_cluster[-1] <= threshold:
                current_cluster.append(level)
            else:
                # –°—Ä–µ–¥–Ω–µ–µ –∞—Ä–∏—Ñ–º–µ—Ç–∏—á–µ—Å–∫–æ–µ –∫–ª–∞—Å—Ç–µ—Ä–∞
                clusters.append(np.mean(current_cluster))
                current_cluster = [level]
        
        if current_cluster:
            clusters.append(np.mean(current_cluster))
        
        return clusters
    
    def _find_best_entries(self, data_frames: Dict[str, pd.DataFrame],
                          aligned_levels: Dict[str, List[float]]) -> List[Dict[str, Any]]:
        """–ù–∞—Ö–æ–¥–∏—Ç –ª—É—á—à–∏–µ —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å–∞."""
        best_entries = []
        
        try:
            primary_df = list(data_frames.values())[0]
            current_price = primary_df['close'].iloc[-1]
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞
            entries = []
            
            # –¢–æ—á–∫–∏ –≤—Ö–æ–¥–∞ —É –ø–æ–¥–¥–µ—Ä–∂–µ–∫
            for support in aligned_levels.get('supports', []):
                if support < current_price:
                    distance = (current_price - support) / current_price
                    
                    if distance < 0.02:  # –í –ø—Ä–µ–¥–µ–ª–∞—Ö 2%
                        entry = {
                            'price': support,
                            'type': 'support',
                            'direction': 'BUY',
                            'distance_pct': distance * 100,
                            'confidence': self._calculate_entry_confidence(support, 'support', data_frames)
                        }
                        entries.append(entry)
            
            # –¢–æ—á–∫–∏ –≤—Ö–æ–¥–∞ —É —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏–π
            for resistance in aligned_levels.get('resistances', []):
                if resistance > current_price:
                    distance = (resistance - current_price) / current_price
                    
                    if distance < 0.02:  # –í –ø—Ä–µ–¥–µ–ª–∞—Ö 2%
                        entry = {
                            'price': resistance,
                            'type': 'resistance',
                            'direction': 'SELL',
                            'distance_pct': distance * 100,
                            'confidence': self._calculate_entry_confidence(resistance, 'resistance', data_frames)
                        }
                        entries.append(entry)
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            entries.sort(key=lambda x: x['confidence'], reverse=True)
            
            # –ë–µ—Ä–µ–º —Ç–æ–ø-3
            best_entries = entries[:3]
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ª—É—á—à–∏—Ö —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞: {e}")
        
        return best_entries
    
    def _calculate_entry_confidence(self, price: float, level_type: str,
                                   data_frames: Dict[str, pd.DataFrame]) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Ç–æ—á–∫–µ –≤—Ö–æ–¥–∞."""
        confidence = 50.0  # –ë–∞–∑–æ–≤–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏–µ —É—Ä–æ–≤–Ω—è –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –¢–§
            tf_count = 0
            
            for tf, df in data_frames.items():
                if len(df) < 20:
                    continue
                
                support, resistance = self._find_key_levels(df)
                
                if level_type == 'support' and support:
                    if abs(support - price) / price < 0.005:  # –í –ø—Ä–µ–¥–µ–ª–∞—Ö 0.5%
                        tf_count += 1
                        # –ë–æ–Ω—É—Å –∑–∞ —Å—Ç–∞—Ä—à–∏–µ –¢–§
                        confidence += self.timeframe_weights.get(tf, 1.0) * 5
                
                if level_type == 'resistance' and resistance:
                    if abs(resistance - price) / price < 0.005:
                        tf_count += 1
                        confidence += self.timeframe_weights.get(tf, 1.0) * 5
            
            # –ë–æ–Ω—É—Å –∑–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¢–§
            confidence += tf_count * 5
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ä–µ–º–Ω—É—é –ø–æ–¥–¥–µ—Ä–∂–∫—É
            primary_df = list(data_frames.values())[0]
            if len(primary_df) >= 50:
                volume_profile = self._create_volume_profile(primary_df)
                for level_price, volume in volume_profile.items():
                    if abs(level_price - price) / price < 0.005:
                        # –í—ã—Å–æ–∫–∏–π –æ–±—ä–µ–º —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                        volume_percentile = volume / max(volume_profile.values())
                        confidence += volume_percentile * 20
                        break
            
            return min(confidence, 100)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤—Ö–æ–¥–∞: {e}")
            return 50.0
    
    def _generate_warnings(self, factor_scores: Dict[ConfluenceFactor, float],
                          timeframe_scores: Dict[str, float]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞."""
        warnings = []
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∏–∑–∫–∏—Ö —Ñ–∞–∫—Ç–æ—Ä–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫
        for factor, score in factor_scores.items():
            if score < 30:
                warnings.append(f"–ù–∏–∑–∫–∞—è –æ—Ü–µ–Ω–∫–∞ —Ñ–∞–∫—Ç–æ—Ä–∞: {factor.value} ({score:.1f})")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
        if timeframe_scores:
            tf_scores_list = list(timeframe_scores.values())
            if len(tf_scores_list) >= 2:
                max_score = max(tf_scores_list)
                min_score = min(tf_scores_list)
                
                if max_score - min_score > 50:
                    warnings.append("–°–∏–ª—å–Ω–æ–µ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ –º–µ–∂–¥—É —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º–∏")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—â–µ–≥–æ —Å—á–µ—Ç–∞
        total_score = np.mean(list(factor_scores.values())) if factor_scores else 0
        if total_score < 40:
            warnings.append("–û–±—â–∏–π —Å—á–µ—Ç –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å–∞ –Ω–∏–∑–∫–∏–π")
        
        return warnings
    
    def _generate_recommendations(self, total_score: float,
                                  aligned_levels: Dict[str, List[float]],
                                  best_entries: List[Dict[str, Any]]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞."""
        recommendations = []
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—â–µ–≥–æ —Å—á–µ—Ç–∞
        if total_score >= 80:
            recommendations.append("–í—ã—Å–æ–∫–∏–π –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å - –æ—Ç–ª–∏—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è –¥–ª—è —Ç–æ—Ä–≥–æ–≤–ª–∏")
        elif total_score >= 60:
            recommendations.append("–•–æ—Ä–æ—à–∏–π –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å - –º–æ–∂–Ω–æ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å —Å–¥–µ–ª–∫–∏")
        elif total_score >= 40:
            recommendations.append("–°—Ä–µ–¥–Ω–∏–π –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å - —Å–æ–±–ª—é–¥–∞–π—Ç–µ –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ—Å—Ç—å")
        else:
            recommendations.append("–ù–∏–∑–∫–∏–π –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å - –ª—É—á—à–µ –≤–æ–∑–¥–µ—Ä–∂–∞—Ç—å—Å—è –æ—Ç —Ç–æ—Ä–≥–æ–≤–ª–∏")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —É—Ä–æ–≤–Ω–µ–π
        if aligned_levels.get('supports'):
            support_str = ', '.join([f"${s:.2f}" for s in aligned_levels['supports'][:3]])
            recommendations.append(f"–ö–ª—é—á–µ–≤—ã–µ –ø–æ–¥–¥–µ—Ä–∂–∫–∏: {support_str}")
        
        if aligned_levels.get('resistances'):
            resistance_str = ', '.join([f"${r:.2f}" for r in aligned_levels['resistances'][:3]])
            recommendations.append(f"–ö–ª—é—á–µ–≤—ã–µ —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è: {resistance_str}")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞
        if best_entries:
            entry = best_entries[0]
            recommendations.append(
                f"–õ—É—á—à–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞: {entry['direction']} @ ${entry['price']:.2f} "
                f"(—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {entry['confidence']:.1f}%)"
            )
        
        return recommendations
    
    def _determine_trend(self, df: pd.DataFrame) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç—Ä–µ–Ω–¥ –Ω–∞ DataFrame."""
        try:
            if len(df) < 20:
                return "ranging"
            
            closes = df['close'].values[-20:]
            highs = df['high'].values[-20:]
            lows = df['low'].values[-20:]
            
            # –°–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ
            ma_short = np.mean(closes[-5:])
            ma_medium = np.mean(closes[-10:])
            ma_long = np.mean(closes)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç—Ä–µ–Ω–¥
            if ma_short > ma_medium > ma_long and closes[-1] > ma_short:
                return "strong_bullish"
            elif ma_short > ma_medium and closes[-1] > ma_short:
                return "bullish"
            elif ma_short < ma_medium < ma_long and closes[-1] < ma_short:
                return "strong_bearish"
            elif ma_short < ma_medium and closes[-1] < ma_short:
                return "bearish"
            else:
                return "ranging"
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–∞: {e}")
            return "ranging"
    
    def _calculate_rsi(self, prices: pd.Series, period: int = 14) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç RSI."""
        try:
            if len(prices) < period + 1:
                return 50.0
            
            delta = prices.diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean().iloc[-1]
            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean().iloc[-1]
            
            if loss == 0:
                return 100.0
            
            rs = gain / loss
            rsi = 100 - (100 / (1 + rs))
            
            return rsi
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ RSI: {e}")
            return 50.0
    
    def _calculate_macd(self, prices: pd.Series) -> Tuple[float, float]:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç MACD."""
        try:
            if len(prices) < 26:
                return 0.0, 0.0
            
            exp1 = prices.ewm(span=12, adjust=False).mean()
            exp2 = prices.ewm(span=26, adjust=False).mean()
            macd = exp1 - exp2
            signal = macd.ewm(span=9, adjust=False).mean()
            
            return macd.iloc[-1], signal.iloc[-1]
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ MACD: {e}")
            return 0.0, 0.0
    
    def _calculate_bollinger_bands(self, prices: pd.Series) -> Tuple[float, float]:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç Bollinger Bands."""
        try:
            if len(prices) < 20:
                return prices.iloc[-1] * 1.02, prices.iloc[-1] * 0.98
            
            sma = prices.rolling(window=20).mean().iloc[-1]
            std = prices.rolling(window=20).std().iloc[-1]
            
            upper = sma + (std * 2)
            lower = sma - (std * 2)
            
            return upper, lower
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ Bollinger Bands: {e}")
            return prices.iloc[-1] * 1.02, prices.iloc[-1] * 0.98
    
    def _log_results(self, result: ConfluenceAnalysisResult):
        """–õ–æ–≥–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞."""
        confluence = result.confluence_score
        
        logger.info(f"‚úÖ –ö–æ–Ω—Ñ–ª—é—ç–Ω—Å –¥–ª—è {result.symbol}:")
        logger.info(f"   üéØ –û–±—â–∏–π —Å—á–µ—Ç: {confluence.total_score:.1f} ({confluence.level.value})")
        logger.info(f"   üìä –§–∞–∫—Ç–æ—Ä—ã:")
        
        for factor, score in confluence.factors.items():
            logger.info(f"     ‚Ä¢ {factor.value}: {score:.1f}")
        
        if result.aligned_levels:
            supports = result.aligned_levels.get('supports', [])
            resistances = result.aligned_levels.get('resistances', [])
            logger.info(f"   üõ°Ô∏è  –°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω—ã–µ —É—Ä–æ–≤–Ω–∏: {len(supports)}S / {len(resistances)}R")
        
        if result.best_entries:
            logger.info(f"   üéØ –õ—É—á—à–∏–µ —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞: {len(result.best_entries)}")
            for entry in result.best_entries:
                logger.info(f"     ‚Ä¢ {entry['direction']} @ ${entry['price']:.2f} "
                           f"(—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {entry['confidence']:.1f}%)")
        
        if result.warnings:
            logger.info(f"   ‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: {len(result.warnings)}")
            for warning in result.warnings:
                logger.info(f"     ‚Ä¢ {warning}")
    
    def _create_empty_result(self, symbol: str, primary_timeframe: str) -> ConfluenceAnalysisResult:
        """–°–æ–∑–¥–∞–µ—Ç –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö."""
        return ConfluenceAnalysisResult(
            symbol=symbol,
            primary_timeframe=primary_timeframe,
            timestamp=datetime.now(),
            confluence_score=ConfluenceScore(
                total_score=0,
                level=ConfluenceLevel.VERY_WEAK,
                factors={},
                timeframes={},
                details={'error': '–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞'}
            ),
            aligned_levels={},
            best_entries=[],
            warnings=["–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å–∞"],
            recommendations=["–°–æ–±–µ—Ä–∏—Ç–µ –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"]
        )
    
    def _clean_cache(self):
        """–û—á–∏—â–∞–µ—Ç —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ –∏–∑ –∫–µ—à–∞."""
        if len(self.cache) > self.cache_max_size:
            keys_to_remove = list(self.cache.keys())[:len(self.cache) - self.cache_max_size]
            for key in keys_to_remove:
                del self.cache[key]
    
    def get_statistics(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–∞–±–æ—Ç—ã –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä–∞."""
        avg_score = np.mean(self.stats['average_scores']) if self.stats['average_scores'] else 0
        
        return {
            'version': self.VERSION,
            'total_analyses': self.stats['total_analyses'],
            'cache_hits': self.stats['cache_hits'],
            'cache_size': len(self.cache),
            'cache_hit_rate': self.stats['cache_hits'] / max(self.stats['total_analyses'], 1),
            'average_confluence_score': avg_score,
            'errors_count': len(self.stats['errors']),
            'recent_errors': self.stats['errors'][-5:] if self.stats['errors'] else [],
            'configuration': {
                'min_timeframes': self.min_timeframes,
                'weight_timeframes': self.weight_timeframes,
                'use_volume_profile': self.use_volume_profile,
                'use_indicators': self.use_indicators,
                'use_patterns': self.use_patterns,
                'use_price_action': self.use_price_action,
                'use_market_structure': self.use_market_structure,
                'alignment_threshold': self.alignment_threshold
            }
        }

# ============================================================================
# –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï
# ============================================================================

if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥—É–ª—è –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å–∞
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ ConfluenceCalculator...")
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
    np.random.seed(42)
    
    data_frames = {}
    
    # 15 –º–∏–Ω—É—Ç
    dates_15m = pd.date_range('2024-01-01', periods=300, freq='15min')
    prices_15m = 50000 + np.cumsum(np.random.randn(300) * 50)
    
    data_frames['15m'] = pd.DataFrame({
        'open': prices_15m - np.random.rand(300) * 50,
        'high': prices_15m + np.random.rand(300) * 75,
        'low': prices_15m - np.random.rand(300) * 75,
        'close': prices_15m,
        'volume': np.random.rand(300) * 1000 + 500
    }, index=dates_15m)
    
    # 1 —á–∞—Å
    dates_1h = pd.date_range('2024-01-01', periods=200, freq='1h')
    prices_1h = 50000 + np.cumsum(np.random.randn(200) * 100)
    
    data_frames['1h'] = pd.DataFrame({
        'open': prices_1h - np.random.rand(200) * 100,
        'high': prices_1h + np.random.rand(200) * 150,
        'low': prices_1h - np.random.rand(200) * 150,
        'close': prices_1h,
        'volume': np.random.rand(200) * 1000 + 500
    }, index=dates_1h)
    
    # 4 —á–∞—Å–∞
    dates_4h = pd.date_range('2024-01-01', periods=100, freq='4h')
    prices_4h = 50000 + np.cumsum(np.random.randn(100) * 200)
    
    data_frames['4h'] = pd.DataFrame({
        'open': prices_4h - np.random.rand(100) * 200,
        'high': prices_4h + np.random.rand(100) * 300,
        'low': prices_4h - np.random.rand(100) * 300,
        'close': prices_4h,
        'volume': np.random.rand(100) * 1000 + 500
    }, index=dates_4h)
    
    # 1 –¥–µ–Ω—å
    dates_1d = pd.date_range('2024-01-01', periods=50, freq='1d')
    prices_1d = 50000 + np.cumsum(np.random.randn(50) * 500)
    
    data_frames['1d'] = pd.DataFrame({
        'open': prices_1d - np.random.rand(50) * 400,
        'high': prices_1d + np.random.rand(50) * 600,
        'low': prices_1d - np.random.rand(50) * 600,
        'close': prices_1d,
        'volume': np.random.rand(50) * 1000 + 500
    }, index=dates_1d)
    
    # –°–æ–∑–¥–∞–µ–º –∏ —Ç–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä
    calculator = ConfluenceCalculator(
        min_timeframes=2,
        weight_timeframes=True,
        use_volume_profile=True,
        use_indicators=True,
        use_patterns=True,
        use_price_action=True,
        use_market_structure=True,
        alignment_threshold=0.7
    )
    
    result = calculator.analyze(data_frames, "BTC/USDT", "1h")
    
    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å–∞:")
    print(f"   –û–±—â–∏–π —Å—á–µ—Ç: {result.confluence_score.total_score:.1f}")
    print(f"   –£—Ä–æ–≤–µ–Ω—å: {result.confluence_score.level.value}")
    
    print(f"\n   –§–∞–∫—Ç–æ—Ä—ã:")
    for factor, score in result.confluence_score.factors.items():
        print(f"     ‚Ä¢ {factor.value}: {score:.1f}")
    
    if result.aligned_levels:
        print(f"\n   –°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω—ã–µ —É—Ä–æ–≤–Ω–∏:")
        supports = result.aligned_levels.get('supports', [])
        resistances = result.aligned_levels.get('resistances', [])
        if supports:
            print(f"     –ü–æ–¥–¥–µ—Ä–∂–∫–∏: {', '.join([f'${s:.2f}' for s in supports])}")
        if resistances:
            print(f"     –°–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è: {', '.join([f'${r:.2f}' for r in resistances])}")
    
    if result.best_entries:
        print(f"\n   –õ—É—á—à–∏–µ —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞:")
        for entry in result.best_entries:
            print(f"     ‚Ä¢ {entry['direction']} @ ${entry['price']:.2f} "
                  f"(—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {entry['confidence']:.1f}%, –¥–∏—Å—Ç–∞–Ω—Ü–∏—è: {entry['distance_pct']:.2f}%)")
    
    if result.warnings:
        print(f"\n   ‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è:")
        for warning in result.warnings:
            print(f"     ‚Ä¢ {warning}")
    
    if result.recommendations:
        print(f"\n   üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        for rec in result.recommendations:
            print(f"     ‚Ä¢ {rec}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä–∞
    stats = calculator.get_statistics()
    print(f"\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä–∞:")
    print(f"   –í—Å–µ–≥–æ –∞–Ω–∞–ª–∏–∑–æ–≤: {stats['total_analyses']}")
    print(f"   –°—Ä–µ–¥–Ω–∏–π —Å—á–µ—Ç –∫–æ–Ω—Ñ–ª—é—ç–Ω—Å–∞: {stats['average_confluence_score']:.1f}")
    print(f"   –ü–æ–ø–∞–¥–∞–Ω–∏–π –≤ –∫–µ—à: {stats['cache_hits']}")
    print(f"   –†–∞–∑–º–µ—Ä –∫–µ—à–∞: {stats['cache_size']}")
    
    print("\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
