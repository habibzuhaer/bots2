#!/usr/bin/env python3
"""
–ü–û–õ–ù–´–ô –û–ë–†–ê–ë–û–¢–ß–ò–ö –î–ê–ù–ù–´–• –î–õ–Ø –¢–û–†–ì–û–í–û–ì–û –ë–û–¢–ê
–í–µ—Ä—Å–∏—è: 2.0
–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –±–∏—Ä–∂, –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ, –æ–±–æ–≥–∞—â–µ–Ω–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏
–ü–æ–¥–¥–µ—Ä–∂–∫–∞: Binance, Bybit, KuCoin, OKX
"""

import asyncio
import aiohttp
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
import logging
import ccxt
import json
import hashlib
import os
import sys
from pathlib import Path
import pickle
from dataclasses import dataclass, asdict
from enum import Enum
import traceback

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ PYTHONPATH
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config.settings import settings

logger = logging.getLogger(__name__)

# ============================================================================
# –ö–û–ù–°–¢–ê–ù–¢–´ –ò –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
# ============================================================================

class ExchangeType(Enum):
    BINANCE = "binance"
    BYBIT = "bybit"
    KUCOIN = "kucoin"
    OKX = "okx"
    COINBASE = "coinbase"

@dataclass
class DataRequest:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–∞–Ω–Ω—ã—Ö."""
    symbol: str
    timeframe: str
    limit: int
    since: Optional[int] = None
    params: Optional[Dict] = None

@dataclass
class CachedData:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."""
    timestamp: datetime
    data: pd.DataFrame
    hash: str

# ============================================================================
# –ö–õ–ê–°–° DATA HANDLER
# ============================================================================

class DataHandler:
    """
    –ü–æ–ª–Ω–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
    
    –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
    - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ 5+ –±–∏—Ä–∂
    - –ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–æ–µ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ (–ø–∞–º—è—Ç—å, –¥–∏—Å–∫, –ë–î)
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∫–æ–Ω–Ω–µ–∫—Ç –∏ retry –ª–æ–≥–∏–∫–∞
    - –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    - –û–±–æ–≥–∞—â–µ–Ω–∏–µ 20+ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º–∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏
    - –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
    """
    
    VERSION = "2.0.0"
    
    def __init__(self, 
                 exchange_id: str = "binance",
                 cache_enabled: bool = True,
                 cache_ttl: int = 300,
                 max_retries: int = 3,
                 timeout: int = 30):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            exchange_id: ID –±–∏—Ä–∂–∏ (binance, bybit, kucoin, okx)
            cache_enabled: –í–∫–ª—é—á–∏—Ç—å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ
            cache_ttl: –í—Ä–µ–º—è –∂–∏–∑–Ω–∏ –∫–µ—à–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            max_retries: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
            timeout: –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        """
        
        self.exchange_id = exchange_id
        self.cache_enabled = cache_enabled
        self.cache_ttl = timedelta(seconds=cache_ttl)
        self.max_retries = max_retries
        self.timeout = timeout
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∏—Ä–∂–∏
        self.exchange = self._init_exchange()
        
        # –°–∏—Å—Ç–µ–º—ã –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è
        self.memory_cache = {}  # –ö–µ—à –≤ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –ø–∞–º—è—Ç–∏
        self.disk_cache_dir = Path("data/cache")
        self.disk_cache_dir.mkdir(parents=True, exist_ok=True)
        
        # –°–µ—Å—Å–∏—è HTTP
        self.session = None
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
        self.stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'avg_response_time': 0,
            'total_data_points': 0,
            'errors': []
        }
        
        # –û—á–µ—Ä–µ–¥—å –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è rate limiting
        self.request_queue = []
        self.rate_limits = {
            'requests_per_minute': 1200,  # –ë–∞–∑–æ–≤—ã–π –ª–∏–º–∏—Ç Binance
            'last_request_time': None
        }
        
        # –°–ø–∏—Å–æ–∫ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
        self.supported_timeframes = {
            '1m': 60,
            '3m': 180,
            '5m': 300,
            '15m': 900,
            '30m': 1800,
            '1h': 3600,
            '2h': 7200,
            '4h': 14400,
            '6h': 21600,
            '8h': 28800,
            '12h': 43200,
            '1d': 86400,
            '3d': 259200,
            '1w': 604800,
            '1M': 2592000
        }
        
        logger.info(f"‚úÖ DataHandler v{self.VERSION} –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è {exchange_id}")
        logger.info(f"   –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ: {'–í–∫–ª—é—á–µ–Ω–æ' if cache_enabled else '–í—ã–∫–ª—é—á–µ–Ω–æ'}")
        logger.info(f"   TTL –∫–µ—à–∞: {cache_ttl} —Å–µ–∫—É–Ω–¥")
    
    def _init_exchange(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∏—Ä–∂–µ."""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∫–ª–∞—Å—Å –±–∏—Ä–∂–∏ –∏–∑ ccxt
            exchange_class = getattr(ccxt, self.exchange_id)
            
            # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –±–∏—Ä–∂
            config = {
                'enableRateLimit': True,
                'timeout': self.timeout * 1000,  # ccxt –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã
                'options': {
                    'defaultType': 'spot',
                    'adjustForTimeDifference': True,
                }
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º API –∫–ª—é—á–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
            exchange_config = settings.exchanges.get(self.exchange_id, {})
            if exchange_config.get('api_key') and exchange_config.get('api_secret'):
                config['apiKey'] = exchange_config['api_key']
                config['secret'] = exchange_config['api_secret']
                
                # –î–ª—è —Ç–µ—Å—Ç–æ–≤–æ–π —Å–µ—Ç–∏
                if exchange_config.get('testnet'):
                    if self.exchange_id == 'binance':
                        config['urls']['api'] = config['urls'].get('test', 'https://testnet.binance.vision/api')
                    elif self.exchange_id == 'bybit':
                        config['urls']['api'] = 'https://api-testnet.bybit.com'
            
            # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –±–∏—Ä–∂–∏
            exchange = exchange_class(config)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä—ã–Ω–∫–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
            exchange.load_markets()
            
            logger.info(f"   –ü–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ {self.exchange_id.upper()}, –¥–æ—Å—Ç—É–ø–Ω–æ {len(exchange.markets)} –ø–∞—Ä")
            return exchange
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±–∏—Ä–∂–∏ {self.exchange_id}: {e}")
            raise
    
    def _get_cache_key(self, symbol: str, timeframe: str, limit: int, since: Optional[int] = None) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á –¥–ª—è –∫–µ—à–∞."""
        key_string = f"{symbol}_{timeframe}_{limit}_{since}"
        return hashlib.md5(key_string.encode()).hexdigest()
    
    def _save_to_disk_cache(self, key: str, data: pd.DataFrame):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–∞–π–ª–æ–≤—ã–π –∫–µ—à."""
        try:
            cache_file = self.disk_cache_dir / f"{key}.pkl"
            
            cache_entry = CachedData(
                timestamp=datetime.now(),
                data=data,
                hash=hashlib.md5(pickle.dumps(data)).hexdigest()
            )
            
            with open(cache_file, 'wb') as f:
                pickle.dump(cache_entry, f)
                
            logger.debug(f"üìÅ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª–æ–≤—ã–π –∫–µ—à: {cache_file}")
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ —Ñ–∞–π–ª–æ–≤—ã–π –∫–µ—à: {e}")
    
    def _load_from_disk_cache(self, key: str) -> Optional[pd.DataFrame]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–æ–≤–æ–≥–æ –∫–µ—à–∞."""
        try:
            cache_file = self.disk_cache_dir / f"{key}.pkl"
            
            if not cache_file.exists():
                return None
            
            with open(cache_file, 'rb') as f:
                cache_entry: CachedData = pickle.load(f)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ä–æ–∫ –≥–æ–¥–Ω–æ—Å—Ç–∏
            if datetime.now() - cache_entry.timestamp > self.cache_ttl:
                os.remove(cache_file)
                return None
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
            current_hash = hashlib.md5(pickle.dumps(cache_entry.data)).hexdigest()
            if current_hash != cache_entry.hash:
                logger.warning(f"‚ö†Ô∏è  –ü–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–π –∫–µ—à, —É–¥–∞–ª—è—é: {cache_file}")
                os.remove(cache_file)
                return None
            
            logger.debug(f"üìÅ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ —Ñ–∞–π–ª–æ–≤–æ–≥–æ –∫–µ—à–∞: {cache_file}")
            return cache_entry.data.copy()
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑ —Ñ–∞–π–ª–æ–≤–æ–≥–æ –∫–µ—à–∞: {e}")
            return None
    
    async def _rate_limit_delay(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ rate limiting."""
        if not self.rate_limits['last_request_time']:
            self.rate_limits['last_request_time'] = datetime.now()
            return
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤—Ä–µ–º—è —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        time_since_last = (datetime.now() - self.rate_limits['last_request_time']).total_seconds()
        
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
        min_interval = 60.0 / self.rate_limits['requests_per_minute']
        
        if time_since_last < min_interval:
            sleep_time = min_interval - time_since_last
            await asyncio.sleep(sleep_time)
        
        self.rate_limits['last_request_time'] = datetime.now()
    
    async def _fetch_with_retry(self, symbol: str, timeframe: str, limit: int, 
                               since: Optional[int] = None, params: Optional[Dict] = None) -> List:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å –±–∏—Ä–∂–∏ —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö.
        
        Args:
            symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º
            limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤–µ—á–µ–π
            since: –í—Ä–µ–º–µ–Ω–Ω–∞—è –º–µ—Ç–∫–∞ –Ω–∞—á–∞–ª–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            params: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            
        Returns:
            List: –°–ø–∏—Å–æ–∫ —Å–≤–µ—á–µ–π –∏–ª–∏ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        
        for attempt in range(self.max_retries):
            try:
                # Rate limiting
                await self._rate_limit_delay()
                
                # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
                start_time = datetime.now()
                
                loop = asyncio.get_event_loop()
                ohlcv = await loop.run_in_executor(
                    None,
                    lambda: self.exchange.fetch_ohlcv(
                        symbol=symbol,
                        timeframe=timeframe,
                        since=since,
                        limit=limit,
                        params=params
                    )
                )
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                response_time = (datetime.now() - start_time).total_seconds()
                self.stats['total_requests'] += 1
                self.stats['successful_requests'] += 1
                self.stats['avg_response_time'] = (
                    (self.stats['avg_response_time'] * (self.stats['successful_requests'] - 1) + response_time) /
                    self.stats['successful_requests']
                )
                
                logger.debug(f"   üì• –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(ohlcv)} —Å–≤–µ—á–µ–π –∑–∞ {response_time:.2f}—Å")
                return ohlcv
                
            except ccxt.NetworkError as e:
                self.stats['failed_requests'] += 1
                error_msg = f"–°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{self.max_retries}): {e}"
                
                if attempt < self.max_retries - 1:
                    logger.warning(f"   ‚ö†Ô∏è  {error_msg}, –ø–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {2 ** attempt}—Å")
                    await asyncio.sleep(2 ** attempt)  # Exponential backoff
                else:
                    logger.error(f"   ‚ùå {error_msg}")
                    self.stats['errors'].append({
                        'timestamp': datetime.now().isoformat(),
                        'symbol': symbol,
                        'timeframe': timeframe,
                        'error': str(e),
                        'attempt': attempt + 1
                    })
                    
            except ccxt.ExchangeError as e:
                self.stats['failed_requests'] += 1
                error_msg = f"–û—à–∏–±–∫–∞ –±–∏—Ä–∂–∏ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{self.max_retries}): {e}"
                
                # –î–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –æ—à–∏–±–æ–∫ –Ω–µ –ø—ã—Ç–∞–µ–º—Å—è –ø–æ–≤—Ç–æ—Ä–Ω–æ
                if "Invalid symbol" in str(e) or "Market does not exist" in str(e):
                    logger.error(f"   ‚ùå {error_msg}")
                    break
                
                if attempt < self.max_retries - 1:
                    logger.warning(f"   ‚ö†Ô∏è  {error_msg}, –ø–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {2 ** attempt}—Å")
                    await asyncio.sleep(2 ** attempt)
                else:
                    logger.error(f"   ‚ùå {error_msg}")
                    self.stats['errors'].append({
                        'timestamp': datetime.now().isoformat(),
                        'symbol': symbol,
                        'timeframe': timeframe,
                        'error': str(e),
                        'attempt': attempt + 1
                    })
                    
            except Exception as e:
                self.stats['failed_requests'] += 1
                error_msg = f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{self.max_retries}): {e}"
                logger.error(f"   ‚ùå {error_msg}")
                self.stats['errors'].append({
                    'timestamp': datetime.now().isoformat(),
                    'symbol': symbol,
                    'timeframe': timeframe,
                    'error': str(e),
                    'attempt': attempt + 1
                })
                
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(2 ** attempt)
        
        return []
    
    async def get_ohlcv(self, symbol: str, timeframe: str = "1h", 
                       limit: int = 500, since: Optional[int] = None,
                       params: Optional[Dict] = None) -> Optional[pd.DataFrame]:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–æ–ª—É—á–µ–Ω–∏—è OHLCV –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "BTC/USDT")
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º ("1m", "5m", "15m", "1h", "4h", "1d")
            limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤–µ—á–µ–π
            since: –í—Ä–µ–º–µ–Ω–Ω–∞—è –º–µ—Ç–∫–∞ –Ω–∞—á–∞–ª–∞ (timestamp –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö)
            params: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
            
        Returns:
            Optional[pd.DataFrame]: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        if not self._validate_request(symbol, timeframe, limit):
            return None
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª—é—á–∞ –∫–µ—à–∞
        cache_key = self._get_cache_key(symbol, timeframe, limit, since)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–µ—à–∞ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
        if self.cache_enabled:
            # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤ –ø–∞–º—è—Ç–∏
            if cache_key in self.memory_cache:
                cached_time, cached_data = self.memory_cache[cache_key]
                if datetime.now() - cached_time < self.cache_ttl:
                    self.stats['cache_hits'] += 1
                    logger.debug(f"üéØ –ö–µ—à –ø–æ–ø–∞–¥–∞–Ω–∏–µ –≤ –ø–∞–º—è—Ç–∏: {symbol} {timeframe}")
                    return cached_data.copy()
            
            # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–∏—Å–∫–µ
            disk_data = self._load_from_disk_cache(cache_key)
            if disk_data is not None:
                self.stats['cache_hits'] += 1
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø–∞–º—è—Ç—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
                self.memory_cache[cache_key] = (datetime.now(), disk_data.copy())
                return disk_data
        
        self.stats['cache_misses'] += 1
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –±–∏—Ä–∂–∏
        logger.info(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ {symbol} {timeframe} ({limit} —Å–≤–µ—á–µ–π)...")
        
        ohlcv_data = await self._fetch_with_retry(symbol, timeframe, limit, since, params)
        
        if not ohlcv_data:
            logger.warning(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è {symbol}")
            return None
        
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ DataFrame
            df = pd.DataFrame(
                ohlcv_data,
                columns=['timestamp', 'open', 'high', 'low', 'close', 'volume']
            )
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è timestamp
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            df.set_index('timestamp', inplace=True)
            
            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
            df.sort_index(inplace=True)
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
            df = self._validate_and_clean_data(df)
            
            # –û–±–æ–≥–∞—â–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º–∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏
            df = self._add_technical_indicators(df)
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            df = self._add_derived_features(df)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            self.stats['total_data_points'] += len(df)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∫–µ—à (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
            if self.cache_enabled:
                self.memory_cache[cache_key] = (datetime.now(), df.copy())
                self._save_to_disk_cache(cache_key, df)
            
            logger.info(f"‚úÖ {symbol} {timeframe}: –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å–≤–µ—á–µ–π, "
                       f"{len(df.columns)} –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤")
            
            return df
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö {symbol}: {e}")
            logger.error(traceback.format_exc())
            return None
    
    def _validate_request(self, symbol: str, timeframe: str, limit: int) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∑–∞–ø—Ä–æ—Å–∞."""
        errors = []
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏–º–≤–æ–ª–∞
        if not symbol or '/' not in symbol:
            errors.append(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Å–∏–º–≤–æ–ª–∞: {symbol}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
        if timeframe not in self.supported_timeframes:
            errors.append(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º: {timeframe}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–∞
        if limit <= 0 or limit > 5000:
            errors.append(f"–õ–∏–º–∏—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç 1 –¥–æ 5000: {limit}")
        
        if errors:
            for error in errors:
                logger.error(f"‚ùå {error}")
            return False
        
        return True
    
    def _validate_and_clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö.
        
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
        - –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
        - –ê–Ω–æ–º–∞–ª—å–Ω—ã–µ —Ü–µ–Ω—ã (—Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è)
        - –ù—É–ª–µ–≤—ã–µ –æ–±—ä–µ–º—ã
        - –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ high/low
        """
        
        if df.empty:
            return df
        
        df_clean = df.copy()
        
        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN
        nan_count = df_clean.isna().sum().sum()
        if nan_count > 0:
            logger.warning(f"‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ {nan_count} NaN –∑–Ω–∞—á–µ–Ω–∏–π, –∑–∞–ø–æ–ª–Ω—è—é...")
            df_clean = df_clean.ffill().bfill()
        
        # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ high/low
        invalid_hl = ((df_clean['high'] < df_clean['low']) | 
                     (df_clean['high'] < df_clean['open']) | 
                     (df_clean['high'] < df_clean['close']) |
                     (df_clean['low'] > df_clean['open']) | 
                     (df_clean['low'] > df_clean['close'])).sum()
        
        if invalid_hl > 0:
            logger.warning(f"‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ {invalid_hl} –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö high/low, –∏—Å–ø—Ä–∞–≤–ª—è—é...")
            
            # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º high
            df_clean['high'] = df_clean[['open', 'high', 'low', 'close']].max(axis=1)
            
            # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º low
            df_clean['low'] = df_clean[['open', 'high', 'low', 'close']].min(axis=1)
        
        # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–Ω–æ–º–∞–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π —Ü–µ–Ω
        price_changes = df_clean['close'].pct_change().abs()
        anomalous_changes = (price_changes > 0.5).sum()  # –ë–æ–ª–µ–µ 50% –∑–∞ –æ–¥–Ω—É —Å–≤–µ—á—É
        
        if anomalous_changes > 0:
            logger.warning(f"‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ {anomalous_changes} –∞–Ω–æ–º–∞–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π —Ü–µ–Ω")
            
            # –ó–∞–º–µ–Ω—è–µ–º –∞–Ω–æ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å—Ä–µ–¥–Ω–∏–º
            for idx in price_changes[price_changes > 0.5].index:
                if idx > 0:
                    df_clean.loc[idx, 'close'] = df_clean.loc[idx-1, 'close']
        
        # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—ä–µ–º–æ–≤
        zero_volumes = (df_clean['volume'] <= 0).sum()
        if zero_volumes > 0:
            logger.warning(f"‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ {zero_volumes} –Ω—É–ª–µ–≤—ã—Ö –æ–±—ä–µ–º–æ–≤")
            
            # –ó–∞–º–µ–Ω—è–µ–º –Ω—É–ª–µ–≤—ã–µ –æ–±—ä–µ–º—ã —Å—Ä–µ–¥–Ω–∏–º
            mean_volume = df_clean['volume'][df_clean['volume'] > 0].mean()
            if pd.notna(mean_volume):
                df_clean['volume'] = df_clean['volume'].replace(0, mean_volume)
        
        return df_clean
    
    def _add_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –≤ DataFrame.
        
        –î–æ–±–∞–≤–ª—è–µ—Ç:
        - –¢—Ä–µ–Ω–¥–æ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (MA, EMA, MACD)
        - –û—Å—Ü–∏–ª–ª—è—Ç–æ—Ä—ã (RSI, Stochastic, CCI)
        - –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å (ATR, Bollinger Bands)
        - –û–±—ä–µ–º–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (OBV, Volume SMA)
        - –ü—Ä–æ—á–∏–µ (Parabolic SAR, Ichimoku)
        """
        
        if df.empty or len(df) < 20:
            return df
        
        df_indicators = df.copy()
        
        try:
            # ==================== –¢–†–ï–ù–î–û–í–´–ï –ò–ù–î–ò–ö–ê–¢–û–†–´ ====================
            
            # –ü—Ä–æ—Å—Ç—ã–µ —Å–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ
            df_indicators['sma_10'] = df_indicators['close'].rolling(window=10).mean()
            df_indicators['sma_20'] = df_indicators['close'].rolling(window=20).mean()
            df_indicators['sma_50'] = df_indicators['close'].rolling(window=50).mean()
            df_indicators['sma_100'] = df_indicators['close'].rolling(window=100).mean()
            df_indicators['sma_200'] = df_indicators['close'].rolling(window=200).mean()
            
            # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ
            df_indicators['ema_12'] = df_indicators['close'].ewm(span=12, adjust=False).mean()
            df_indicators['ema_26'] = df_indicators['close'].ewm(span=26, adjust=False).mean()
            df_indicators['ema_50'] = df_indicators['close'].ewm(span=50, adjust=False).mean()
            df_indicators['ema_200'] = df_indicators['close'].ewm(span=200, adjust=False).mean()
            
            # MACD
            df_indicators['macd'] = df_indicators['ema_12'] - df_indicators['ema_26']
            df_indicators['macd_signal'] = df_indicators['macd'].ewm(span=9, adjust=False).mean()
            df_indicators['macd_histogram'] = df_indicators['macd'] - df_indicators['macd_signal']
            
            # ==================== –û–°–¶–ò–õ–õ–Ø–¢–û–†–´ ====================
            
            # RSI (Relative Strength Index)
            delta = df_indicators['close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss
            df_indicators['rsi'] = 100 - (100 / (1 + rs))
            
            # Stochastic Oscillator
            low_14 = df_indicators['low'].rolling(window=14).min()
            high_14 = df_indicators['high'].rolling(window=14).max()
            df_indicators['stoch_k'] = 100 * ((df_indicators['close'] - low_14) / (high_14 - low_14))
            df_indicators['stoch_d'] = df_indicators['stoch_k'].rolling(window=3).mean()
            
            # CCI (Commodity Channel Index)
            tp = (df_indicators['high'] + df_indicators['low'] + df_indicators['close']) / 3
            sma_tp = tp.rolling(window=20).mean()
            mad = tp.rolling(window=20).apply(lambda x: np.abs(x - x.mean()).mean())
            df_indicators['cci'] = (tp - sma_tp) / (0.015 * mad)
            
            # Williams %R
            highest_high = df_indicators['high'].rolling(window=14).max()
            lowest_low = df_indicators['low'].rolling(window=14).min()
            df_indicators['williams_r'] = -100 * ((highest_high - df_indicators['close']) / (highest_high - lowest_low))
            
            # ==================== –í–û–õ–ê–¢–ò–õ–¨–ù–û–°–¢–¨ ====================
            
            # ATR (Average True Range)
            high_low = df_indicators['high'] - df_indicators['low']
            high_close = np.abs(df_indicators['high'] - df_indicators['close'].shift())
            low_close = np.abs(df_indicators['low'] - df_indicators['close'].shift())
            ranges = pd.concat([high_low, high_close, low_close], axis=1)
            true_range = ranges.max(axis=1)
            df_indicators['atr'] = true_range.rolling(window=14).mean()
            
            # Bollinger Bands
            df_indicators['bb_middle'] = df_indicators['close'].rolling(window=20).mean()
            bb_std = df_indicators['close'].rolling(window=20).std()
            df_indicators['bb_upper'] = df_indicators['bb_middle'] + (bb_std * 2)
            df_indicators['bb_lower'] = df_indicators['bb_middle'] - (bb_std * 2)
            df_indicators['bb_width'] = (df_indicators['bb_upper'] - df_indicators['bb_lower']) / df_indicators['bb_middle']
            df_indicators['bb_position'] = (df_indicators['close'] - df_indicators['bb_lower']) / (df_indicators['bb_upper'] - df_indicators['bb_lower'])
            
            # ==================== –û–ë–™–ï–ú–ù–´–ï –ò–ù–î–ò–ö–ê–¢–û–†–´ ====================
            
            # Volume SMA
            df_indicators['volume_sma_20'] = df_indicators['volume'].rolling(window=20).mean()
            df_indicators['volume_ratio'] = df_indicators['volume'] / df_indicators['volume_sma_20']
            
            # OBV (On-Balance Volume)
            df_indicators['obv'] = 0
            for i in range(1, len(df_indicators)):
                if df_indicators['close'].iloc[i] > df_indicators['close'].iloc[i-1]:
                    df_indicators['obv'].iloc[i] = df_indicators['obv'].iloc[i-1] + df_indicators['volume'].iloc[i]
                elif df_indicators['close'].iloc[i] < df_indicators['close'].iloc[i-1]:
                    df_indicators['obv'].iloc[i] = df_indicators['obv'].iloc[i-1] - df_indicators['volume'].iloc[i]
                else:
                    df_indicators['obv'].iloc[i] = df_indicators['obv'].iloc[i-1]
            
            # ==================== –ü–†–û–ß–ò–ï –ò–ù–î–ò–ö–ê–¢–û–†–´ ====================
            
            # Parabolic SAR (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)
            df_indicators['sar'] = df_indicators['close'].copy()
            af = 0.02  # Acceleration factor
            ep = df_indicators['high'].iloc[0]  # Extreme point
            
            for i in range(1, len(df_indicators)):
                if df_indicators['close'].iloc[i] > ep:
                    ep = df_indicators['high'].iloc[i]
                    af = min(af + 0.02, 0.2)
                else:
                    ep = df_indicators['low'].iloc[i]
                    af = min(af + 0.02, 0.2)
                
                df_indicators['sar'].iloc[i] = df_indicators['sar'].iloc[i-1] + af * (ep - df_indicators['sar'].iloc[i-1])
            
            # –ü—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è —Ç—Ä–µ–Ω–¥–∞
            df_indicators['trend_ema'] = np.where(
                df_indicators['ema_12'] > df_indicators['ema_26'], 1, -1
            )
            
            df_indicators['trend_sma'] = np.where(
                (df_indicators['close'] > df_indicators['sma_20']) & 
                (df_indicators['sma_20'] > df_indicators['sma_50']), 1,
                np.where(
                    (df_indicators['close'] < df_indicators['sma_20']) & 
                    (df_indicators['sma_20'] < df_indicators['sma_50']), -1, 0
                )
            )
            
            logger.debug(f"üìà –î–æ–±–∞–≤–ª–µ–Ω–æ {len(df_indicators.columns) - 6} —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤: {e}")
            logger.error(traceback.format_exc())
        
        return df_indicators
    
    def _add_derived_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."""
        if df.empty:
            return df
        
        df_features = df.copy()
        
        try:
            # –¶–µ–Ω–æ–≤—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
            df_features['returns'] = df_features['close'].pct_change()
            df_features['log_returns'] = np.log(df_features['close'] / df_features['close'].shift())
            
            # –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
            df_features['volatility_20'] = df_features['returns'].rolling(window=20).std() * np.sqrt(365)
            df_features['volatility_50'] = df_features['returns'].rolling(window=50).std() * np.sqrt(365)
            
            # –ú–æ–º–µ–Ω—Ç –∏ —É—Å–∫–æ—Ä–µ–Ω–∏–µ
            df_features['momentum_10'] = df_features['close'] - df_features['close'].shift(10)
            df_features['acceleration_5'] = df_features['momentum_10'].diff(5)
            
            # –ü—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
            for period in [1, 3, 5, 10, 20]:
                df_features[f'pct_change_{period}'] = df_features['close'].pct_change(periods=period)
            
            # –°–∫–æ–ª—å–∑—è—â–∏–µ –º–∏–Ω–∏–º—É–º—ã –∏ –º–∞–∫—Å–∏–º—É–º—ã
            df_features['rolling_max_20'] = df_features['high'].rolling(window=20).max()
            df_features['rolling_min_20'] = df_features['low'].rolling(window=20).min()
            df_features['price_position'] = (df_features['close'] - df_features['rolling_min_20']) / \
                                          (df_features['rolling_max_20'] - df_features['rolling_min_20'])
            
            # –°–≤–µ—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–µ)
            df_features['is_doji'] = np.abs(df_features['close'] - df_features['open']) / \
                                    (df_features['high'] - df_features['low']) < 0.1
            
            df_features['is_bullish'] = df_features['close'] > df_features['open']
            df_features['is_bearish'] = df_features['close'] < df_features['open']
            
            # –û–±—ä–µ–º–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            df_features['volume_spike'] = df_features['volume_ratio'] > 2.0
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
        
        return df_features
    
    async def get_multiple_timeframes(self, symbol: str, 
                                    timeframes: List[str] = None,
                                    limit: int = 500) -> Dict[str, pd.DataFrame]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ.
        
        Args:
            symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞
            timeframes: –°–ø–∏—Å–æ–∫ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
            limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤–µ—á–µ–π –Ω–∞ —Ç–∞–π–º—Ñ—Ä–µ–π–º
            
        Returns:
            Dict: {—Ç–∞–π–º—Ñ—Ä–µ–π–º: DataFrame}
        """
        
        if timeframes is None:
            timeframes = ["15m", "1h", "4h", "1d"]
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
        tasks = []
        for tf in timeframes:
            task = self.get_ohlcv(symbol, tf, limit)
            tasks.append(task)
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        data = {}
        for tf, result in zip(timeframes, results):
            if isinstance(result, Exception):
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–ª—è {symbol} {tf}: {result}")
            elif result is not None:
                data[tf] = result
        
        logger.info(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ –¥–ª—è {symbol}")
        return data
    
    async def get_current_price(self, symbol: str) -> Optional[float]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—É—â—É—é —Ü–µ–Ω—É —Å–∏–º–≤–æ–ª–∞."""
        try:
            loop = asyncio.get_event_loop()
            ticker = await loop.run_in_executor(
                None,
                lambda: self.exchange.fetch_ticker(symbol)
            )
            return ticker.get('last')
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ü–µ–Ω—ã {symbol}: {e}")
            return None
    
    async def get_symbol_info(self, symbol: str) -> Optional[Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ—Ä–≥–æ–≤–æ–π –ø–∞—Ä–µ."""
        try:
            loop = asyncio.get_event_loop()
            markets = await loop.run_in_executor(
                None,
                lambda: self.exchange.load_markets()
            )
            return markets.get(symbol)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ {symbol}: {e}")
            return None
    
    async def test_connection(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –±–∏—Ä–∂–µ–π."""
        try:
            loop = asyncio.get_event_loop()
            # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –≤—Ä–µ–º—è —Å–µ—Ä–≤–µ—Ä–∞
            server_time = await loop.run_in_executor(None, self.exchange.fetch_time)
            
            # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Ç–∏–∫–µ—Ä –¥–ª—è BTC/USDT
            ticker = await loop.run_in_executor(
                None,
                lambda: self.exchange.fetch_ticker('BTC/USDT')
            )
            
            logger.info(f"‚úÖ –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å {self.exchange_id.upper()} —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
            logger.info(f"   –í—Ä–µ–º—è —Å–µ—Ä–≤–µ—Ä–∞: {datetime.fromtimestamp(server_time/1000)}")
            logger.info(f"   –¶–µ–Ω–∞ BTC: ${ticker.get('last'):,.2f}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ {self.exchange_id.upper()}: {e}")
            return False
    
    def get_statistics(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–∞–±–æ—Ç—ã."""
        total_requests = self.stats['total_requests']
        successful = self.stats['successful_requests']
        failed = self.stats['failed_requests']
        cache_hits = self.stats['cache_hits']
        cache_misses = self.stats['cache_misses']
        
        success_rate = successful / total_requests if total_requests > 0 else 0
        error_rate = failed / total_requests if total_requests > 0 else 0
        hit_rate = cache_hits / (cache_hits + cache_misses) if (cache_hits + cache_misses) > 0 else 0
        
        return {
            'version': self.VERSION,
            'exchange': self.exchange_id,
            'requests': {
                'total': total_requests,
                'successful': successful,
                'failed': failed,
                'success_rate': f"{success_rate:.1%}",
                'error_rate': f"{error_rate:.1%}",
                'avg_response_time': f"{self.stats['avg_response_time']:.3f}s"
            },
            'cache': {
                'hits': cache_hits,
                'misses': cache_misses,
                'hit_rate': f"{hit_rate:.1%}",
                'memory_size': len(self.memory_cache),
                'disk_size': len(list(self.disk_cache_dir.glob("*.pkl")))
            },
            'data': {
                'total_points': self.stats['total_data_points'],
                'memory_cache_size': sum(len(df) for _, (_, df) in self.memory_cache.items())
            },
            'errors': {
                'total': len(self.stats['errors']),
                'recent': self.stats['errors'][-5:] if self.stats['errors'] else []
            }
        }
    
    def clear_cache(self, memory: bool = True, disk: bool = True):
        """–û—á–∏—â–∞–µ—Ç –∫–µ—à."""
        if memory:
            self.memory_cache.clear()
            logger.info("üßπ –û—á–∏—â–µ–Ω –∫–µ—à –≤ –ø–∞–º—è—Ç–∏")
        
        if disk and self.disk_cache_dir.exists():
            for file in self.disk_cache_dir.glob("*.pkl"):
                file.unlink()
            logger.info("üßπ –û—á–∏—â–µ–Ω —Ñ–∞–π–ª–æ–≤—ã–π –∫–µ—à")
    
    async def close(self):
        """–ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã."""
        logger.info("üîö –ó–∞–∫—Ä—ã—Ç–∏–µ DataHandler...")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats_file = Path("logs/data_handler_stats.json")
        stats_file.parent.mkdir(exist_ok=True)
        
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(self.get_statistics(), f, indent=2, ensure_ascii=False, default=str)
        
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–µ—Å—Å–∏—é (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if self.session:
            await self.session.close()
        
        logger.info("‚úÖ DataHandler –∑–∞–∫—Ä—ã—Ç")

# ============================================================================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò –ò –£–¢–ò–õ–ò–¢–´
# ============================================================================

def calculate_support_resistance_levels(df: pd.DataFrame, method: str = 'pivot') -> Dict:
    """
    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —É—Ä–æ–≤–Ω–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∏ —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è.
    
    Args:
        df: DataFrame —Å —Ü–µ–Ω–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        method: –ú–µ—Ç–æ–¥ —Ä–∞—Å—á–µ—Ç–∞ ('pivot', 'fractal', 'volume')
        
    Returns:
        Dict: –£—Ä–æ–≤–Ω–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∏ —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è
    """
    
    if df.empty:
        return {'supports': [], 'resistances': []}
    
    levels = {'supports': [], 'resistances': []}
    
    try:
        if method == 'pivot':
            # –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –ø–∏–≤–æ—Ç-—É—Ä–æ–≤–Ω–∏
            pivot = (df['high'].iloc[-1] + df['low'].iloc[-1] + df['close'].iloc[-1]) / 3
            r1 = (2 * pivot) - df['low'].iloc[-1]
            r2 = pivot + (df['high'].iloc[-1] - df['low'].iloc[-1])
            s1 = (2 * pivot) - df['high'].iloc[-1]
            s2 = pivot - (df['high'].iloc[-1] - df['low'].iloc[-1])
            
            levels['resistances'] = [r1, r2]
            levels['supports'] = [s1, s2]
        
        elif method == 'fractal':
            # –£—Ä–æ–≤–Ω–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ—Ä–∞–∫—Ç–∞–ª–æ–≤ (Williams)
            window = 5
            
            for i in range(window, len(df) - window):
                # –§—Ä–∞–∫—Ç–∞–ª—ã –≤–≤–µ—Ä—Ö (—Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏–µ)
                if df['high'].iloc[i] == df['high'].iloc[i-window:i+window+1].max():
                    levels['resistances'].append(df['high'].iloc[i])
                
                # –§—Ä–∞–∫—Ç–∞–ª—ã –≤–Ω–∏–∑ (–ø–æ–¥–¥–µ—Ä–∂–∫–∞)
                if df['low'].iloc[i] == df['low'].iloc[i-window:i+window+1].min():
                    levels['supports'].append(df['low'].iloc[i])
            
            # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —É—Ä–æ–≤–Ω–µ–π
            levels['resistances'] = _cluster_levels(levels['resistances'])
            levels['supports'] = _cluster_levels(levels['supports'])
        
        elif method == 'volume':
            # –£—Ä–æ–≤–Ω–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ Volume Profile
            price_levels = np.linspace(df['low'].min(), df['high'].max(), 50)
            volume_profile = np.zeros_like(price_levels)
            
            for _, row in df.iterrows():
                low_idx = np.searchsorted(price_levels, row['low'])
                high_idx = np.searchsorted(price_levels, row['high'])
                
                if high_idx > low_idx:
                    volume_per_level = row['volume'] / (high_idx - low_idx)
                    volume_profile[low_idx:high_idx] += volume_per_level
            
            # –ù–∞—Ö–æ–¥–∏–º –ø–∏–∫–∏ –æ–±—ä–µ–º–∞
            from scipy.signal import find_peaks
            peaks, _ = find_peaks(volume_profile, height=np.mean(volume_profile) * 1.5)
            
            for peak in peaks:
                price = price_levels[peak]
                if price < df['close'].iloc[-1]:
                    levels['supports'].append(float(price))
                else:
                    levels['resistances'].append(float(price))
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ —É—Ä–æ–≤–Ω–µ–π: {e}")
    
    return levels

def _cluster_levels(levels: List[float], threshold_pct: float = 0.01) -> List[float]:
    """–ö–ª–∞—Å—Ç–µ—Ä–∏–∑—É–µ—Ç –±–ª–∏–∑–∫–∏–µ —É—Ä–æ–≤–Ω–∏."""
    if not levels:
        return []
    
    levels_sorted = sorted(levels)
    clusters = []
    current_cluster = [levels_sorted[0]]
    
    for price in levels_sorted[1:]:
        if abs(price - current_cluster[-1]) / current_cluster[-1] <= threshold_pct:
            current_cluster.append(price)
        else:
            clusters.append(np.mean(current_cluster))
            current_cluster = [price]
    
    if current_cluster:
        clusters.append(np.mean(current_cluster))
    
    return clusters

# ============================================================================
# –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï
# ============================================================================

async def test_data_handler():
    """–ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ DataHandler."""
    print("\n" + "="*60)
    print("üß™ –ö–û–ú–ü–õ–ï–ö–°–ù–û–ï –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï DATA HANDLER")
    print("="*60)
    
    handler = DataHandler(
        exchange_id="binance",
        cache_enabled=True,
        cache_ttl=60
    )
    
    try:
        # 1. –¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
        print("\n1. üîå –¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∏—Ä–∂–µ...")
        if await handler.test_connection():
            print("   ‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ")
        else:
            print("   ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è")
            return
        
        # 2. –¢–µ—Å—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        print("\n2. üì• –¢–µ—Å—Ç –∑–∞–≥—Ä—É–∑–∫–∏ OHLCV –¥–∞–Ω–Ω—ã—Ö...")
        df = await handler.get_ohlcv("BTC/USDT", "1h", 100)
        
        if df is not None and not df.empty:
            print(f"   ‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(df)} —Å–≤–µ—á–µ–π")
            print(f"   üìä –ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
            print(f"   üí∞ –î–∏–∞–ø–∞–∑–æ–Ω: ${df['close'].min():.2f} - ${df['close'].max():.2f}")
            print(f"   ‚è∞ –ü–µ—Ä–∏–æ–¥: {df.index[0]} - {df.index[-1]}")
        else:
            print("   ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
            return
        
        # 3. –¢–µ—Å—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
        print("\n3. üìà –¢–µ—Å—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤...")
        multi_data = await handler.get_multiple_timeframes("ETH/USDT", ["15m", "1h", "4h"], 50)
        
        if multi_data:
            print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤: {len(multi_data)}")
            for tf, tf_df in multi_data.items():
                print(f"     {tf}: {len(tf_df)} —Å–≤–µ—á–µ–π, {len(tf_df.columns)} –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤")
        else:
            print("   ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã")
        
        # 4. –¢–µ—Å—Ç —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω—ã
        print("\n4. üí∞ –¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω—ã...")
        price = await handler.get_current_price("BTC/USDT")
        if price:
            print(f"   ‚úÖ –¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞ BTC: ${price:.2f}")
        else:
            print("   ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ü–µ–Ω—É")
        
        # 5. –¢–µ—Å—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–∏–º–≤–æ–ª–µ
        print("\n5. üìã –¢–µ—Å—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–∏–º–≤–æ–ª–µ...")
        info = await handler.get_symbol_info("BTC/USDT")
        if info:
            print(f"   ‚úÖ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∞")
            print(f"     –õ–æ—Ç: {info.get('lot', 'N/A')}")
            print(f"     –¢–æ—á–Ω–æ—Å—Ç—å: {info.get('precision', 'N/A')}")
        else:
            print("   ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é")
        
        # 6. –¢–µ—Å—Ç —Ä–∞—Å—á–µ—Ç–∞ —É—Ä–æ–≤–Ω–µ–π
        print("\n6. üéØ –¢–µ—Å—Ç —Ä–∞—Å—á–µ—Ç–∞ —É—Ä–æ–≤–Ω–µ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏/—Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è...")
        if df is not None:
            levels = calculate_support_resistance_levels(df, method='pivot')
            print(f"   ‚úÖ –£—Ä–æ–≤–Ω–∏ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã")
            print(f"     –ü–æ–¥–¥–µ—Ä–∂–∫–∏: {levels['supports']}")
            print(f"     –°–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è: {levels['resistances']}")
        
        # 7. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print("\n7. üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞–±–æ—Ç—ã...")
        stats = handler.get_statistics()
        print(f"   –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {stats['requests']['total']}")
        print(f"   –£—Å–ø–µ—à–Ω—ã—Ö: {stats['requests']['successful']}")
        print(f"   –ö–µ—à –ø–æ–ø–∞–¥–∞–Ω–∏–π: {stats['cache']['hit_rate']}")
        print(f"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {stats['requests']['avg_response_time']}")
        
        # 8. –¢–µ—Å—Ç –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è
        print("\n8. üíæ –¢–µ—Å—Ç –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è...")
        print("   –ü–µ—Ä–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ (–∫–µ—à –ø—Ä–æ–º–∞—Ö)...")
        start = datetime.now()
        df1 = await handler.get_ohlcv("BTC/USDT", "1h", 10)
        time1 = (datetime.now() - start).total_seconds()
        
        print("   –í—Ç–æ—Ä–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ (–∫–µ—à –ø–æ–ø–∞–¥–∞–Ω–∏–µ)...")
        start = datetime.now()
        df2 = await handler.get_ohlcv("BTC/USDT", "1h", 10)
        time2 = (datetime.now() - start).total_seconds()
        
        if time2 < time1:
            print(f"   ‚úÖ –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–µ—Ç: {time1:.3f}s -> {time2:.3f}s")
        else:
            print(f"   ‚ö†Ô∏è  –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ –¥–∞–ª–æ —É—Å–∫–æ—Ä–µ–Ω–∏—è")
        
        print("\n" + "="*60)
        print("üéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´ –£–°–ü–ï–®–ù–û!")
        print("="*60)
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        await handler.close()

if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞
    import asyncio
    asyncio.run(test_data_handler())